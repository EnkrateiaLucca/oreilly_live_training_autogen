<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to LLM-Based Agents</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

        class: center, middle

        # Getting Started with LLM Agents using LangChain
        ### By Lucas Soares

        ---
        <div class="slide">
          <h1>Lucas Soares</h1>
          <div style="display: flex; align-items: center;">
            <ul style="flex: 1;">
              <li>ML Engineer</li>
              <br>
              <br>
              <br>
              <br>
            </ul>
            <img src="../notebooks/assets-resources/profile_pic.png" width="300" style="margin-left: 20px;">
          </div>
        </div>
        ---

        <div class="slide">
          <h1>Lucas Soares</h1>
          <div style="display: flex; align-items: center;">
            <ul style="flex: 1;">
              <li>ML Engineer</li>
              <br>
              <li>Instructor at O'Reilly Media</li>
              <br>
              <br>
            </ul>
            <img src="../notebooks/assets-resources/profile_pic.png" width="300" style="margin-left: 20px;">
          </div>
        </div>

        ---

        <div class="slide">
          <h1>Lucas Soares</h1>
          <div style="display: flex; align-items: center;">
            <ul style="flex: 1;">
              <li>ML Engineer</li>
              <br>
              <li>Instructor at O'Reilly Media</li>
              <br>
              <li>Curious about all things intelligence</li>
            </ul>
            <img src="../notebooks/assets-resources/profile_pic.png" width="300" style="margin-left: 20px;">
          </div>
        </div>

        ---

        # Table of Contents

        - __Agents as Thought + Action__
        
        --

        - __Agents:__ Definition & Tools

        --

        - __Agents in 3 Complexity Levels__

        --

        - __OpenAI's Function Calling API__

        --
        
        - __LangChain Framework__

        --

        - __Building Agents with LangChain__

        --

        - __Lots of Demos! :)__

        ---

        # Thought + Action

        --

        - How do we do stuff?

        ---

        # Thought + Action

        - How do we do stuff? We __think__ and we __act__
        
        --

        - Example: Decision-making process for attending a live-training

        --

        - __Thought__: "I want to learn about agents"
        
        --
        
        - __Action__: "Go to the internet and research cool 
        platforms where I can learn about agents"
        
        --

        - __Thought__: "O'Reilly has some awesome courses and live-trainings"
        
        --
        
        - __Action__: "Look up O'Reilly courses"
        
        --
        
        - __Thought__: "Live-trainings by instructor Lucas are awesome"
        
        --
        
        - __Action__: "Schedule live-training about agents with instructor Lucas Soares"

        ---
        class: center, middle

        # Thinking: 
        
        
        ## What to do + planning (order, priority..)
        
        ---
        class: center, middle

        # Acting: 
        
        
        ## used __tools: search, browser, etc...__

        ---

        # What is an Agent?

        --

        ## LLM

        ---

        # What is an Agent?


        ## LLM + Tools

        --

        <div style="display: flex; align-items: center;">
          <h4>LLM</h4><p> = predicts next word/sentence</p>
          <img src="../notebooks/assets-resources/llm_predicts_pancakes.png" width="300" style="margin-left:100px">
        </div>

        --

        <div style="display: flex; align-items: center;">
          <h4>Tool</h4><p> = perform actions in the real-world</p>
          <img src="../notebooks/assets-resources/pancake_maker.png" width="300" style="margin-left: 50px;">
        </div>


        ---
        
        # LLMs can use tools!

        - ['Toolformer'](https://arxiv.org/pdf/2302.04761.pdf)

        --

        <img style="width: 400px; margin-left:-5px "src="../notebooks/assets-resources/toolformer.png">

        <p style="font-size: 14px; margin-top: -10px;">
          <sup>[1]</sup> <a href="https://arxiv.org/pdf/2302.04761.pdf">(Schick u. a., o. J., 2023)</a>
        </p>

        ---
        # Interleaving Thoughts and Actions

        - [ReACT](https://arxiv.org/pdf/2210.03629.pdf): LLMs for __RE__asoning & __ACT__ion.

        <img style="width: 800px" src="../notebooks/assets-resources/react_paper_figure.png" >

        <p style="font-size: 14px; margin-top: -10px;">
          <sup>[2]</sup> <a href="https://arxiv.org/pdf/2210.03629.pdf">Yao, X., et al. (2023)</a>
        </p>

        ---
        
        ## Agents Are Getting Popular

        --

        - [A Survey on Large Language Model based
        Autonomous Agents](https://arxiv.org/pdf/2308.11432.pdf)  

        <img style="width: 600px" src="../notebooks/assets-resources/agents_growth_trends.png">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[3]</sup> <a href="https://arxiv.org/pdf/2308.11432.pdf" >(Wang et al. 2023)</a>

        ---
        # Popular Agent Implementations

        --
        
        - [BabyAGI](https://github.com/yoheinakajima/babyagi):
        separate planning and execution steps

        <img style="width: 600px" src="../notebooks/assets-resources/baby-agi.png" alt="">

        <p style="font-size: 14px; margin-top: -10px;">
          <sup>[4]</sup> <a href="https://github.com/yoheinakajima/babyagi" >BabyAGI</a>

        ---
        # Popular Agent Implementations

        - [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT): created for long-running, open-ended goals

        <img style="width: 800px" src="../notebooks/assets-resources/autogpt.png" alt="">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[5]</sup> <a href="https://github.com/Significant-Gravitas/AutoGPT" >AutoGPT</a>

        ---
        # Popular Agent Implementations

        - [GPT-Researcher](https://github.com/assafelovic/gpt-researcher?ref=blog.langchain.dev): produce detailed, factual and unbiased research reports

        <img style="width: 300px" src="../notebooks/assets-resources/gpt-researcher.png" alt="">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[6]</sup> <a href="https://github.com/assafelovic/gpt-researcher?ref=blog.langchain.dev">GPT-Researcher</a> 
        ---
        # Popular Agent Implementations

        - [Custom GPTs](https://openai.com/blog/introducing-gpts) for specific tasks  

        <img style="width: 500px" src="../notebooks/assets-resources/custom-gpts.png" alt="">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[7]</sup> <a href="https://openai.com/blog/introducing-gpts">Custom GPT OpenAI Blog Post</a>
        
        ---
        class: center, middle
        # Agents in 3 Levels of Complexity

        ---

        # Level 1: LLM + functions inside the prompt 

        --
        
        - Inspired by ['Toolformer'](https://arxiv.org/pdf/2302.04761.pdf)

        <img style="width: 400px "src="../notebooks/assets-resources/toolformer.png">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[1]</sup> <a href="https://arxiv.org/pdf/2302.04761.pdf">(Schick u. a., o. J., 2023)</a>

        ---

        # Level 1: LLM + functions inside the prompt


        ```python
        from openai import OpenAI
        client = OpenAI()
        
        def get_response(prompt_question, model="gpt-3.5-turbo-16k"):
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": "You are a helpful research and programming assistant"},
                        {"role": "user", "content": prompt_question}]
            )
            
            return response.choices[0].message.content

        def create_directory(directory_name):
            subprocess.run(["mkdir", directory_name])

        def create_file(file_name):
            subprocess.run(["touch", file_name])

        def list_files():
            subprocess.run(["ls"])
        ```

        ---

        # Level 1: LLM + functions inside the prompt

        ```python

          task_description = "Create a folder called 'lucas-the-agent-master'. Inside that folder, create a file called 'the-10-master-rules.md"
          output = get_response(f"""Given this task: {task_description}, \n
                                  Consider you have access to the following functions:
                                  
          def create_directory(directory_name):
              '''Function that creates a directory given a directory name.'''
              subprocess.run(["mkdir", directory_name])
          
          def create_file(file_name):
              '''Function that creates a file given a file name.'''
              subprocess.run(["touch", file_name])
          
          def list_files():
            '''Function that lists all files in the current directory.'''
              subprocess.run(["ls"])
          
          Your output should be the first function to be executed to complete the task containing the necessary arguments.
          The OUTPUT SHOULD ONLY BE THE PYTHON FUNCTION CALL and NOTHING ELSE.
          """)
          
          Markdown(output)

          # Output:
          # create_directory('lucas-the-agent-master')
        ```

        ---

        # Level 1: LLM + functions inside the prompt

        -  Now, all we need is to find a way to execute this function. 

        --

        - We can use Python's built in `exec` method for that:
        
        --
        ```python
        # Output:
        # create_directory('lucas-the-agent-master')
        exec(output)
        !ls -d */ | grep lucas
        # Output:
        # lucas-the-agent-master/
        ```
        
        ---

        # Limitations

        --

        - __Probabilistic outputs__ make function calls unreliable
        
        --

        - Need for __structured ways to prepare the inputs__ of 
        the function calls
        
        --
        
        - Putting entire functions inside text prompts is clunky and
        __non-scalable__
        
        --

        - Solution? __OpenAI Functions__!
        
        ---
        class: center, middle

        # OpenAI's Function Calling API
        
        ---

        # OpenAI Function Calling

        --

        - [OpenAI function calling](https://platform.openai.com/docs/guides/function-calling):

        ---

        # OpenAI Function Calling


        - [OpenAI function calling](https://platform.openai.com/docs/guides/function-calling): standard way to connect models to outside tools.

        --

        ### Steps

        --

        1. Call the model with the user query and a set of functions defined in the functions parameter.
        
        --
        
        2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema.
        
        --
        
        3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.
        
        --
        
        4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[8]</sup><a href="https://platform.openai.com/docs/guides/function-calling">OpenAI Function Calling Docs</a>
        </p>
        

        ---

        # Step 1 & 2

        --
        
        ```python
        import json
        
        def create_directory(directory_name):
            # Function to create a directory
            subprocess.run(["mkdir", directory_name])
            return json.dumps({"directory_name": directory_name})
        
        tool_create_directory = {
            "type": "function",
            "function": {
                "name": "create_directory",
                "description": "Create a directory given a directory name.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "directory_name": {
                            "type": "string",
                            "description": "The name of the directory to create.",
                        }
                    },
                    "required": ["directory_name"],
                },
            },
        }
        tools = [tool_create_directory]

        ```

        ---

        # Step 1 & 2

        ```python

        def run_terminal_task():
            messages = [{"role": "user", "content": 
            "Create a folder called 'lucas-the-agent-master'."}]
            tools = [tool_create_directory]  
            response = client.chat.completions.create(
                model="gpt-3.5-turbo-16k",
                messages=messages,
                tools=tools,
                tool_choice="auto",
            )
            response_message = response.choices[0].message
            tool_calls = response_message.tool_calls
            # Check if the model called a function
            if tool_calls:
                # Proceed to step 3
        ```
        ---
        # Step 3: Parse and execute the function

        ```python
          available_functions = {
            "create_directory": create_directory,
        }
        messages.append(response_message)
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            function_response = function_to_call(
                directory_name=function_args.get("directory_name"),
            )
            messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )
        ```

        ---
        # Step 4: Summarize Results Back to User

        ```python
            second_response = client.chat.completions.create(
              model="gpt-3.5-turbo-16k",
              messages=messages,
          )
          return second_response

          output = run_terminal_task()
        ```
        ---
        class: center, middle

        # Ready to Implement Your Own Functions?

        <h2><span style="background-color: lightgreen">
          OpenAI Functions Demo
        </span> </h2>
        
        ---
        class: center, middle

        # Q&A

        ---
        class: center, middle

        # Break 10 Minutes

        ---
        class: center, middle

        # Agents and LangChain

        ---
        # LangChain Implementation

        ```python
        from langchain.agents import create_openai_tools_agent
        from langchain_openai import ChatOpenAI
        from langchain import hub
        from langchain.tools import tool
        from langchain.agents import AgentExecutor
        import subprocess

        @tool
        def create_directory(directory_name):
            """Function that creates a directory with the given name."""
            subprocess.run(["mkdir", directory_name])

        prompt = hub.pull("hwchase17/openai-functions-agent")
        llm = ChatOpenAI(model="gpt-4-0125-preview")
        tools = [create_directory]
        agent = create_openai_tools_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
        agent_executor.invoke({"input": "Create a folder called 'lucas-the-agent-master'."})
        ```
        ---
        # How Can We Effectively Perform Tasks with Agents?

        --

        - [The Agent Loop](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/#:~:text=sweep.dev%20is%20another%20great%20example.%20they%20wrote%20a%20blog%20over%20the%20summer%20describing%20their%20cognitive%20architecture%2C%20including%20a%20fantastic%20diagram.)
          
        <img style="width: 700px" src="../notebooks/assets-resources/agent_loop.png">

        <p style="font-size: 14px; margin-top: 10px;">
          <sup>[9]</sup> <a href="https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/#:~:text=sweep.dev%20is%20another%20great%20example.%20they%20wrote%20a%20blog%20over%20the%20summer%20describing%20their%20cognitive%20architecture%2C%20including%20a%20fantastic%20diagram." >OpenAI's Bet on a Cognitive Architecture</a>
        ---
        # Good Agents are Routers

        --

        - Good examples of 'useful' agents (that implement a more like routing type of architecture than actual agent architecture)

        --

        - LangChain is a framework to implement these types of routing procedures!

        - ['OpenAI's Bet on a Cognitive Architecture'](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/)
        ---

        # What is LangChain?

        --

        - [LangChain](https://python.langchain.com/docs/get_started/introduction) is a framework for building
        context-aware reasoning applications

        --

        - Its main features

        --

          - __Components__: composable tools and integrations 
          for working with language models. 
        --
        

          - __Off-the-shelf chains__: built-in assemblages of components for 
          accomplishing higher-level tasks

          <p style="font-size: 14px; margin-top: 250px;">
            <sup>[10]</sup> <a href="https://python.langchain.com/docs/get_started/introduction" >LangChain Docs</a>
        

        ---

        # Core Elements of LangChain

        --

        ## __Models__

        --

        - Abstractions over LLM APIs (e.g ChatGPT API)

        --

        ```python
        from langchain_openai.chat_models import ChatOpenAI

        chat_model = ChatOpenAI(api_key=os.getenv("OPENAI_API_KEY"), model="gpt-3.5-turbo-1106")

        chat_model.invoke("hi!")
        ```
        
        ---

        # Core Elements of LangChain
        
        ## __Prompt Templates__

        --

        - Abstractions over traditional text prompts for LLMs

        --

        ```python
        from langchain.prompts import ChatPromptTemplate
        prompt = ChatPromptTemplate.from_template("Show me 5 examples of this concept: {concept}")
        prompt.format(concept="animal")
        # Output
        # 'Human: Show me 5 examples of this concept: animal'
        ```
        
        ---

        # Core Elements of LangChain

        ## __Output parser__
        
        --

        - Abstractions for parsing outputs of LLMs 

        --
        
        ```python
        from langchain.schema import BaseOutputParser

        class CommaSeparatedListOutputParser(BaseOutputParser):
            """Parse the output of an LLM call to a comma-separated list."""

            def parse(self, text: str):
                """Parse the output of an LLM call."""
                return text.strip().split(", ")

        CommaSeparatedListOutputParser().parse("hi, bye")
        # Output: ['hi', 'bye']
        ```

        ---

        # LCEL - Putting Components Together

        --

        ## LCEL interface 

        - Interface that leverages the __`|`__ pipe symbol 
        to compose LangChain components

        --
        
        ```python
        from langchain_openai.chat_models import ChatOpenAI
        from langchain.prompts import ChatPromptTemplate
        from langchain.schema.output_parser import StrOutputParser


        model = ChatOpenAI(temperature=0)
        prompt = ChatPromptTemplate.from_template(template="Name 5 concepts related to this: {concept}. The output should be in bullet points.")
        output_parser = StrOutputParser()
        
        chain = prompt | model | output_parser

        chain.invoke({"concept": "probability distribution"})
        # Output
        # - Discrete probability distribution: This concept... 
        # - Continuous probability.... 
        # ...
        ```

        ---
        class: center, middle

        # Practicing the Basics of LangChain
        <h2><span style="background-color: lightgreen">
          LangChain Demo
        </span> </h2>

        ---
        class: center, middle

        # Break

        ---
        
        # Building Agents with LangChain

        --

        ## The Agent Loop 

        --

        <img src="../notebooks/assets-resources/agent_loop.svg" width="800">

        ---
        # Key LangChain Components for Agents

        ## Schema

        --

        - LangChain provides many abstractions for ease of use

        --

        - **AgentAction**: Represents the action an agent should take.

        --

        - **AgentFinish**: Represents the final result to return to the user.
        
        --

        - **Intermediate Steps**: Previous actions and outputs for the current agent run.

        --

        - **Agent**: Chain responsible for deciding the next step, powered by a language model.

        ---

        # Agent Inputs and Outputs

        ## Agent Inputs

        --
        
        - Key-value mapping.

        --

        - Required key: `intermediate_steps`.

        --

        ## Agent Outputs

        --

        - Next actions or final response (AgentActions or AgentFinish).

        --

        - Handled by the output parser.

        ---
        # AgentExecutor

        ## The runtime for a LangChain agent

        ```python
        next_action = agent.get_action(...)
        while next_action != AgentFinish:
            observation = run(next_action)
            next_action = agent.get_action(..., next_action, observation)
        return next_action
        ```

        - Handles complexities like tool errors and logging.

        ---
        class: center, middle

        <h2><span style="background-color: lightgreen">
          LangChain Agents Demo
        </span> </h2>

        ---
        class: center, middle

        # Break

        ---

        # Tools in LangChain

        --

        - Functions that an agent can call.

        --

        - Consists of:

        --
          - Input schema for the tool.

        --

          - Function to run.

        --

        - Important for building a working agent.
        ---

        # Toolkits

        - Groups of 3-5 tools for specific objectives.

        --

        - Example: GitHub toolkit for interacting with GitHub.

        --

        - LangChain provides a wide set of toolkits.

        ---
        class: center, middle

        # Let's Build Agents!

        <h2><span style="background-color: lightgreen">
          LangChain Agents Demo - Github Agent; Tutor Agent; Research Assistant
        </span> </h2>

        ---

        # References

          1. [Toolformer - Schick et al., 2023](https://arxiv.org/pdf/2302.04761.pdf)
          2. [ReACT - Yao, X., et al., 2023](https://arxiv.org/pdf/2210.03629.pdf)
          3. [A Survey on Large Language Model based Autonomous Agents - Wang et al., 2023](https://arxiv.org/pdf/2308.11432.pdf)
          4. [BabyAGI](https://github.com/yoheinakajima/babyagi)
          5. [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
          6. [GPT-Researcher](https://github.com/assafelovic/gpt-researcher?ref=blog.langchain.dev)
          7. [Custom GPTs](https://openai.com/blog/introducing-gpts)
          8. [OpenAI function calling Docs](https://platform.openai.com/docs/guides/function-calling)
          9. [OpenAI's Bet on a Cognitive Architecture](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/#:~:text=sweep.dev%20is%20another%20great%20example.%20they%20wrote%20a%20blog%20over%20the%20summer%20describing%20their%20cognitive%20architecture%2C%20including%20a%20fantastic%20diagram.)
          10. [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)



        ---

        class: center, middle

        # Conclusion
        ## Ready to Build Your Own Agents?        

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>