{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyautogen==0.2.9\n",
    "# !pip install openai==1.10.0\n",
    "# or pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import config_list_from_json, AssistantAgent, UserProxyAgent\n",
    "from autogen.agentchat import GroupChat, GroupChatManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = config_list_from_json('./OAI_CONFIG_LIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, I can help with that. The first step is to search arxiv for the latest papers about GPT-4. Here is a Python script that uses the arxiv API to search for papers about GPT-4. This script will list the titles, authors, and abstracts of the 5 most recent papers. Please run this code in a python environment.\n",
      "\n",
      "``` python\n",
      "import arxiv\n",
      "\n",
      "# Search for papers about GPT-4\n",
      "search = arxiv.Search(\n",
      "  query = \"GPT-4\",\n",
      "  max_results = 5,\n",
      "  sort_by = arxiv.SortCriterion.RecentlySubmitted\n",
      ")\n",
      "\n",
      "# Print out the titles, authors, and abstracts\n",
      "for result in search.results():\n",
      "  print(\"Title: \", result.title)\n",
      "  print(\"Authors: \", result.authors)\n",
      "  print(\"Abstract: \", result.summary)\n",
      "  print(\"\\n---\\n\")\n",
      "```\n",
      "\n",
      "After executing the above code, I will help in identifying potential applications in software based on the abstracts of these papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 7, in <module>\n",
      "    sort_by = arxiv.SortCriterion.RecentlySubmitted\n",
      "  File \"/Users/greatmaster/miniconda3/envs/oreilly-autogen/lib/python3.10/enum.py\", line 437, in __getattr__\n",
      "    raise AttributeError(name) from None\n",
      "AttributeError: RecentlySubmitted\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the error. It seems the arXiv API has been updated, and the attribute for sorting by the recently submitted papers does not exist any longer.\n",
      "\n",
      "We can modify the code to get the latest papers using another attribute. Here is the corrected Python code. Please execute this code for the latest papers on GPT-4.\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "\n",
      "# Search for the most recent papers on GPT-4\n",
      "search = arxiv.Search(\n",
      "  query = \"GPT-4\",\n",
      "  max_results = 5,\n",
      "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
      ")\n",
      "\n",
      "# Print the titles, authors, and summary (Abstract) of each paper\n",
      "for result in search.get():\n",
      "  print(\"Title: \", result.title)\n",
      "  print(\"Authors: \", \", \".join(author.name for author in result.authors))\n",
      "  print(\"Summary: \", result.summary)\n",
      "  print(\"\\n---\\n\")\n",
      "```\n",
      "After running this code, we can further analyze the summaries of the papers to identify potential applications of GPT-4 in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 11, in <module>\n",
      "    for result in search.get():\n",
      "AttributeError: 'Search' object has no attribute 'get'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "I'm sorry for the oversight. The arXiv API in Python has been updated and I made a mistake in the use of it. Here is the corrected code that properly uses the new API to search for papers about GPT-4 and sorts them by submission date. Please execute this code.\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "import arxivpy\n",
      "\n",
      "papers = arxivpy.query(search_query=\"gpt-4\",\n",
      "                       start_index=0,\n",
      "                       max_index=5,\n",
      "                       sort_by=\"submittedDate\",\n",
      "                       sort_order=\"descending\")\n",
      "\n",
      "for paper in papers:\n",
      "    print('Title: {}'.format(paper['title']))\n",
      "    print('Authors: {}'.format(\", \".join(paper['authors'])))\n",
      "    print('Summary: \\n{}\\n'.format(paper['summary']))\n",
      "    print(\"---\" * 20)\n",
      "```\n",
      "\n",
      "This will output the top 5 most recent papers on GPT-4 from arXiv. We can then review the summary of each paper to find potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 2, in <module>\n",
      "    import arxivpy\n",
      "ModuleNotFoundError: No module named 'arxivpy'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize again for the confusion. It appears there was a misunderstanding in the specific package to use. \n",
      "\n",
      "The correct package is 'arxiv' not 'arxivpy'. Here's the revised python code.  This code will pull the latest 5 papers about GPT-4 from arXiv.\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "\n",
      "# Define the search query\n",
      "search_query = 'GPT-4'\n",
      "search = arxiv.Search(\n",
      "    query = search_query,\n",
      "    max_results = 5,\n",
      "    sort_by = arxiv.SortCriterion.SubmittedDate\n",
      ")\n",
      "\n",
      "# Print the papers\n",
      "for result in search.get():\n",
      "    print('\\n---\\n')\n",
      "    print('Title: ', result.title)\n",
      "    print('Authors: ', result.authors)\n",
      "    print('Summary: ', result.summary)\n",
      "```\n",
      "\n",
      "Please run this python code and afterwards, we will identify potential applications in software based on the abstracts of these papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 12, in <module>\n",
      "    for result in search.get():\n",
      "AttributeError: 'Search' object has no attribute 'get'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize once again for the confusion. My previous responses had some issues that I overlooked. Let's use the arxiv-api, for which here is the corrected code. Please execute this:\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "\n",
      "# Define the search query\n",
      "search_query = 'GPT-4'\n",
      "search = arxiv.Search(query=search_query, max_results=5)\n",
      "\n",
      "# Print the papers\n",
      "for result in search.results():\n",
      "    print('\\n---\\n')\n",
      "    print('Title: ', result.title)\n",
      "    print('Authors: ', \", \".join(author.name for author in result.authors))\n",
      "    print('Summary: ', result.summary)\n",
      "```\n",
      "\n",
      "We will assess the abstracts of these papers to determine the conceivable utilization of GPT-4 in software once we have the search findings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "---\n",
      "\n",
      "Title:  Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today\n",
      "Authors:  Zhuo Wang, Rongzhen Li, Bowen Dong, Jie Wang, Xiuxing Li, Ning Liu, Chenhui Mao, Wei Zhang, Liling Dong, Jing Gao, Jianyong Wang\n",
      "Summary:  Recent investigations show that large language models (LLMs), specifically\n",
      "GPT-4, not only have remarkable capabilities in common Natural Language\n",
      "Processing (NLP) tasks but also exhibit human-level performance on various\n",
      "professional and academic benchmarks. However, whether GPT-4 can be directly\n",
      "used in practical applications and replace traditional artificial intelligence\n",
      "(AI) tools in specialized domains requires further experimental validation. In\n",
      "this paper, we explore the potential of LLMs such as GPT-4 to outperform\n",
      "traditional AI tools in dementia diagnosis. Comprehensive comparisons between\n",
      "GPT-4 and traditional AI tools are conducted to examine their diagnostic\n",
      "accuracy in a clinical setting. Experimental results on two real clinical\n",
      "datasets show that, although LLMs like GPT-4 demonstrate potential for future\n",
      "advancements in dementia diagnosis, they currently do not surpass the\n",
      "performance of traditional AI tools. The interpretability and faithfulness of\n",
      "GPT-4 are also evaluated by comparison with real doctors. We discuss the\n",
      "limitations of GPT-4 in its current state and propose future research\n",
      "directions to enhance GPT-4 in dementia diagnosis.\n",
      "\n",
      "---\n",
      "\n",
      "Title:  GPT-4 Can't Reason\n",
      "Authors:  Konstantine Arkoudas\n",
      "Summary:  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\n",
      "improvement across the board over GPT-3.5 (OpenAI's previously best model,\n",
      "which had powered the initial release of ChatGPT). However, despite the\n",
      "genuinely impressive improvement, there are good reasons to be highly skeptical\n",
      "of GPT-4's ability to reason. This position paper discusses the nature of\n",
      "reasoning; criticizes the current formulation of reasoning problems in the NLP\n",
      "community, as well as the way in which LLM reasoning performance is currently\n",
      "evaluated; introduces a small collection of 21 diverse reasoning problems; and\n",
      "performs a detailed qualitative evaluation of GPT-4's performance on those\n",
      "problems. Based on this analysis, the paper concludes that, despite its\n",
      "occasional flashes of analytical brilliance, GPT-4 at present is utterly\n",
      "incapable of reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Title:  Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4\n",
      "Authors:  Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, Yue Zhang\n",
      "Summary:  Harnessing logical reasoning ability is a comprehensive natural language\n",
      "understanding endeavor. With the release of Generative Pretrained Transformer 4\n",
      "(GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn\n",
      "the GPT-4 performance on various logical reasoning tasks. This report analyses\n",
      "multiple logical reasoning datasets, with popular benchmarks like LogiQA and\n",
      "ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice\n",
      "reading comprehension and natural language inference tasks with benchmarks\n",
      "requiring logical reasoning. We further construct a logical reasoning\n",
      "out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4.\n",
      "We also make a performance comparison between ChatGPT and GPT-4. Experiment\n",
      "results show that ChatGPT performs significantly better than the RoBERTa\n",
      "fine-tuning method on most logical reasoning benchmarks. With early access to\n",
      "the GPT-4 API we are able to conduct intense experiments on the GPT-4 model.\n",
      "The results show GPT-4 yields even higher performance on most logical reasoning\n",
      "datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known\n",
      "datasets like LogiQA and ReClor. However, the performance drops significantly\n",
      "when handling newly released and out-of-distribution datasets. Logical\n",
      "reasoning remains challenging for ChatGPT and GPT-4, especially on\n",
      "out-of-distribution and natural language inference datasets. We release the\n",
      "prompt-style logical reasoning datasets as a benchmark suite and name it\n",
      "LogiEval.\n",
      "\n",
      "---\n",
      "\n",
      "Title:  How is ChatGPT's behavior changing over time?\n",
      "Authors:  Lingjiao Chen, Matei Zaharia, James Zou\n",
      "Summary:  GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\n",
      "services. However, when and how these models are updated over time is opaque.\n",
      "Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\n",
      "several diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\n",
      "opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\n",
      "code, 6) US Medical License tests, and 7) visual reasoning. We find that the\n",
      "performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\n",
      "For example, GPT-4 (March 2023) was reasonable at identifying prime vs.\n",
      "composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\n",
      "questions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\n",
      "to follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\n",
      "June than in March in this task. GPT-4 became less willing to answer sensitive\n",
      "questions and opinion survey questions in June than in March. GPT-4 performed\n",
      "better at multi-hop questions in June than in March, while GPT-3.5's\n",
      "performance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\n",
      "mistakes in code generation in June than in March. We provide evidence that\n",
      "GPT-4's ability to follow user instructions has decreased over time, which is\n",
      "one common factor behind the many behavior drifts. Overall, our findings show\n",
      "that the behavior of the \"same\" LLM service can change substantially in a\n",
      "relatively short amount of time, highlighting the need for continuous\n",
      "monitoring of LLMs.\n",
      "\n",
      "---\n",
      "\n",
      "Title:  Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing\n",
      "Authors:  Jawid Ahmad Baktash, Mursal Dawodi\n",
      "Summary:  Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation\n",
      "language model in the GPT series, developed by OpenAI, which promises\n",
      "significant advancements in the field of natural language processing (NLP). In\n",
      "this research article, we have discussed the features of GPT-4, its potential\n",
      "applications, and the challenges that it might face. We have also compared\n",
      "GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one\n",
      "trillion), better multilingual capabilities, improved contextual understanding,\n",
      "and reasoning capabilities than GPT-3. Some of the potential applications of\n",
      "GPT-4 include chatbots, personal assistants, language translation, text\n",
      "summarization, and question-answering. However, GPT-4 poses several challenges\n",
      "and limitations such as computational requirements, data requirements, and\n",
      "ethical concerns.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
