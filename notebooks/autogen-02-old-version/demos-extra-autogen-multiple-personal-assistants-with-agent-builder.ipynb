{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import config_list_from_json\n",
    "\n",
    "config_file_or_env = './OAI_CONFIG_LIST'\n",
    "config_list = config_list_from_json(config_file_or_env)\n",
    "\n",
    "default_llm_config = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"config_list\": config_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "\n",
    "builder  = AgentBuilder(config_file_or_env='./OAI_CONFIG_LIST',\n",
    "                        builder_model=\"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating agents...\n",
      "['AI_ML_Engineer', 'Technical_Content_Creator', 'Personal_Blog_Writer', 'Task_Management_Integrator', 'Research_Analyst'] are generated.\n",
      "==> Generating system message...\n",
      "Preparing system message for AI_ML_Engineer\n",
      "Preparing system message for Technical_Content_Creator\n",
      "Preparing system message for Personal_Blog_Writer\n",
      "Preparing system message for Task_Management_Integrator\n",
      "Preparing system message for Research_Analyst\n",
      "==> Generating description...\n",
      "Preparing description for AI_ML_Engineer\n",
      "Preparing description for Technical_Content_Creator\n",
      "Preparing description for Personal_Blog_Writer\n",
      "Preparing description for Task_Management_Integrator\n",
      "Preparing description for Research_Analyst\n",
      "==> Creating agents...\n",
      "Creating agent AI_ML_Engineer with backbone gpt-4...\n",
      "Creating agent Technical_Content_Creator with backbone gpt-4...\n",
      "Creating agent Personal_Blog_Writer with backbone gpt-4...\n",
      "Creating agent Task_Management_Integrator with backbone gpt-4...\n",
      "Creating agent Research_Analyst with backbone gpt-4...\n",
      "Adding user console proxy...\n"
     ]
    }
   ],
   "source": [
    "personal_instructions = \"\"\"I work as a ML engineer and often have to:\n",
    "- Write code for machine learning tasks like image classification, object detection, ocr, automations with large language model apis like chatgpt or llama2.\n",
    "- Prepare presentations and technical content to present for O'Reilly media live-training courses.\n",
    "- Write blog posts and articles for my personal blog and other publications.\n",
    "- Write code for my personal projects that I put on github\n",
    "- Interact with software to manage my tasks like Jira\n",
    "- Schedule and plan my tasks, events and activities using google calendar\n",
    "- Interact with my Notion databases\n",
    "- Research current open source frameworks related to applying AI to solve problems\n",
    "- Research academic literature on topics like AI, machine learning, human augmentation, neuroscience and others. \"\"\"\n",
    "\n",
    "building_task = \"\"\"Create a multi-agent system to tackle all my personal problems and tasks given these instructions:\n",
    "{personal_instructions}\n",
    "\"\"\"\n",
    "\n",
    "agent_list, agent_configs = builder.build(building_task,\n",
    "                                          default_llm_config={\n",
    "                                              \"config_list\": config_list,\n",
    "                                              \"temperature\": 0},\n",
    "                                          coding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ./save_config_8c1ae13de6d49da4e36ff43c108ff099.json\n",
      "==> Creating agents...\n",
      "Creating agent AI_research_scout with backbone gpt-4...\n",
      "Creating agent AI_paper_analyst with backbone gpt-4...\n",
      "Creating agent gpt4_application_explorer with backbone gpt-4...\n",
      "Creating agent AI_technical_writer with backbone gpt-4...\n",
      "Creating agent AI_system_programmer with backbone gpt-4...\n",
      "Adding user console proxy...\n",
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "Research optimal organizational strategies for the types of activities that I do and write them down in a file named meta-report.txt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAI_technical_writer\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, I can help with that. However, as an AI, I don't perform activities in the same way humans do. I can provide you with a general approach to organizing tasks based on common AI activities such as data analysis, model training, and report writing. Here's a brief outline:\n",
      "\n",
      "1. **Data Analysis:**\n",
      "   - Start by understanding the problem statement and the data required to solve it.\n",
      "   - Collect the data from reliable sources.\n",
      "   - Clean and preprocess the data to make it suitable for analysis.\n",
      "   - Perform exploratory data analysis to understand the patterns and relationships in the data.\n",
      "   - Document your findings.\n",
      "\n",
      "2. **Model Training:**\n",
      "   - Choose the right model based on the problem statement and the data.\n",
      "   - Split the data into training and testing sets.\n",
      "   - Train the model using the training set and tune the hyperparameters.\n",
      "   - Evaluate the model using the testing set.\n",
      "   - Document the model's performance.\n",
      "\n",
      "3. **Report Writing:**\n",
      "   - Start with an introduction that explains the problem statement.\n",
      "   - Describe the data and the exploratory data analysis findings.\n",
      "   - Explain the model choice and the training process.\n",
      "   - Discuss the model's performance and any limitations.\n",
      "   - Conclude with the final thoughts and future work.\n",
      "\n",
      "This is a general approach and might need to be adapted based on the specific task at hand. I'll write this down in a file named meta-report.txt.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAI_system_programmer\u001b[0m (to chat_manager):\n",
      "\n",
      "# filename: write_to_file.py\n",
      "\n",
      "```python\n",
      "# Python code to write the organizational strategies to a file\n",
      "with open('meta-report.txt', 'w') as f:\n",
      "    f.write(\"1. Data Analysis:\\n\")\n",
      "    f.write(\"   - Start by understanding the problem statement and the data required to solve it.\\n\")\n",
      "    f.write(\"   - Collect the data from reliable sources.\\n\")\n",
      "    f.write(\"   - Clean and preprocess the data to make it suitable for analysis.\\n\")\n",
      "    f.write(\"   - Perform exploratory data analysis to understand the patterns and relationships in the data.\\n\")\n",
      "    f.write(\"   - Document your findings.\\n\")\n",
      "    f.write(\"\\n\")\n",
      "    f.write(\"2. Model Training:\\n\")\n",
      "    f.write(\"   - Choose the right model based on the problem statement and the data.\\n\")\n",
      "    f.write(\"   - Split the data into training and testing sets.\\n\")\n",
      "    f.write(\"   - Train the model using the training set and tune the hyperparameters.\\n\")\n",
      "    f.write(\"   - Evaluate the model using the testing set.\\n\")\n",
      "    f.write(\"   - Document the model's performance.\\n\")\n",
      "    f.write(\"\\n\")\n",
      "    f.write(\"3. Report Writing:\\n\")\n",
      "    f.write(\"   - Start with an introduction that explains the problem statement.\\n\")\n",
      "    f.write(\"   - Describe the data and the exploratory data analysis findings.\\n\")\n",
      "    f.write(\"   - Explain the model choice and the training process.\\n\")\n",
      "    f.write(\"   - Discuss the model's performance and any limitations.\\n\")\n",
      "    f.write(\"   - Conclude with the final thoughts and future work.\\n\")\n",
      "```\n",
      "\n",
      "Please save the above code in a file named `write_to_file.py` and run it. This will create a file named `meta-report.txt` with the organizational strategies.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAI_research_scout\u001b[0m (to chat_manager):\n",
      "\n",
      "Great! The code ran successfully. The organizational strategies have been written to the file named `meta-report.txt`. Please check the file to confirm the information. If you need further assistance, feel free to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAI_paper_analyst\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute the task\n",
    "# agents collaborate in a group chat to complete task\n",
    "# combine llms, human inputs, and tools\n",
    "# example: start_task(execution_task, agent_list, llm_config)\n",
    "from autogen import config_list_from_json, GroupChat, GroupChatManager\n",
    "\n",
    "builder  = AgentBuilder(config_file_or_env='./OAI_CONFIG_LIST',\n",
    "                        builder_model=\"gpt-4-1106-preview\")\n",
    "\n",
    "agent_list, agent_configs = builder.load(\"./save_config_8c1ae13de6d49da4e36ff43c108ff099.json\")\n",
    "\n",
    "def start_task(execution_task: str, agent_list: list, personal_instructions: str):\n",
    "    group_chat = GroupChat(agents=agent_list, messages=[], max_round=12)\n",
    "    manager = GroupChatManager(groupchat=group_chat, llm_config={\"config_list\": config_list, **default_llm_config})\n",
    "    teachability = Teachability(\n",
    "        reset_db=False,\n",
    "        path_to_db_dir=\"./tmp/interactive/teachability_db\"\n",
    "        )\n",
    "    teachability.add_to_agent(manager) \n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)\n",
    "\n",
    "\n",
    "personal_instructions = \"\"\"I work as a ML engineer and often have to:\n",
    "- Write code for machine learning tasks like image classification, object detection, ocr, automations with large language model apis like chatgpt or llama2.\n",
    "- Prepare presentations and technical content to present for O'Reilly media live-training courses.\n",
    "- Write blog posts and articles for my personal blog and other publications.\n",
    "- Write code for my personal projects that I put on github\n",
    "- Interact with software to manage my tasks like Jira\n",
    "- Schedule and plan my tasks, events and activities using google calendar\n",
    "- Interact with my Notion databases\n",
    "- Research current open source frameworks related to applying AI to solve problems\n",
    "- Research academic literature on topics like AI, machine learning, human augmentation, neuroscience and others. \"\"\"\n",
    "\n",
    "\n",
    "start_task(\n",
    "    execution_task=\"Research optimal organizational strategies for the types of activities that I do and write them down in a file named meta-report.txt\",\n",
    "    agent_list=agent_list,\n",
    "    personal_instructions=personal_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we can see the task delegated to the research analyst and then redirected to the tecnical content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
