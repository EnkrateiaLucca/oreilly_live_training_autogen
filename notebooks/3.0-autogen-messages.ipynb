{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56da2a3b",
   "metadata": {},
   "source": [
    "# Working with Messages in AutoGen\n",
    "\n",
    "This lesson explores how to work with different types of messages in AutoGen's AgentChat system, demonstrating text-based and multimodal communication between agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5a7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807cd77",
   "metadata": {},
   "source": [
    "## Basic Message Types\n",
    "\n",
    "AutoGen supports various message types for agent communication. Let's explore the main ones:\n",
    "\n",
    "### Text Messages\n",
    "\n",
    "The simplest form of communication is through text messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373a7706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async environment configured for Jupyter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    print(\"Async environment configured for Jupyter.\")\n",
    "except ImportError:\n",
    "    print(\"Please install nest_asyncio with `pip install nest_asyncio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dcc2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "# Create a simple text message\n",
    "greeting_message = TextMessage(\n",
    "    content=\"Hi! Let's analyze some data together!\",\n",
    "    source=\"Data Analyst\"\n",
    ")\n",
    "\n",
    "# Create a more complex text message with technical instructions\n",
    "technical_message = TextMessage(\n",
    "    content=\"Please create a pandas DataFrame with sample sales data\",\n",
    "    source=\"Technical Lead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1264cde",
   "metadata": {},
   "source": [
    "### Multimodal Messages\n",
    "\n",
    "For more complex interactions involving images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7557e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a visualization of our sine wave data. Can you describe the pattern?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to create a sample plot\n",
    "def create_sample_plot():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y = np.sin(x)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y)\n",
    "    plt.title('Sample Sine Wave')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save to BytesIO\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    \n",
    "    return Image.open(buf)\n",
    "\n",
    "# Create a plot and convert it to AutoGen Image\n",
    "plot_image = AGImage(create_sample_plot())\n",
    "\n",
    "# Create a multimodal message with both text and the plot\n",
    "analysis_message = MultiModalMessage(\n",
    "    content=[\n",
    "        \"Here's a visualization of our sine wave data. Can you describe the pattern?\",\n",
    "        plot_image\n",
    "    ],\n",
    "    source=\"user\"\n",
    ")\n",
    "\n",
    "analysis_message.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3754a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful research assistant with \\\n",
    "        a focus on data analysis and visualization.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "response = await assistant.on_messages([analysis_message], cancellation_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3adfa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The visualization shows a sine wave pattern. The wave oscillates smoothly and periodically, starting at zero, rising to a peak of 1, descending through zero to a trough of -1, and then returning to zero. This cycle repeats, indicating a periodic function. The wave completes one full cycle approximately every \\\\(2\\\\pi\\\\) units along the x-axis, which is typical for a sine wave. The amplitude is 1, and the wave is symmetric about the x-axis.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caacbb2",
   "metadata": {},
   "source": [
    "## Working with Internal Events\n",
    "\n",
    "AutoGen also supports internal events for agent communication.\n",
    "\n",
    "- Events are internal messages used for agent communication\n",
    "- They are of type AgentEvent and include:\n",
    "    - ToolCallRequestEvent: For requesting tool calls\n",
    "    - ToolCallExecutionEvent: For tool call results\n",
    "- Events are typically:\n",
    "    - Created by the agent\n",
    "    - Stored in Response.inner_messages\n",
    "    - Can be used to communicate with UIs and other components\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a336d",
   "metadata": {},
   "source": [
    "## Practical Example: Data Analysis Conversation\n",
    "\n",
    "Here's a complete example showing how different message types can be used in a data analysis scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36454db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: Let's analyze our monthly sales data for 2023\n",
      "\n",
      "Data Summary: Summary Statistics:\n",
      "                      date       sales\n",
      "count                   12   12.000000\n",
      "mean   2023-07-15 22:00:00  157.500000\n",
      "min    2023-01-31 00:00:00  100.000000\n",
      "25%    2023-04-22 12:00:00  140.000000\n",
      "50%    2023-07-15 12:00:00  160.000000\n",
      "75%    2023-10-07 18:00:00  180.000000\n",
      "max    2023-12-31 00:00:00  200.000000\n",
      "std                    NaN   29.271457\n",
      "\n",
      "Visualization Message: Here's our sales trend visualization. We can observe a peak in June followed by a gradual decline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/y8s3fc655417629rqwgxkhx80000gn/T/ipykernel_93705/1942987545.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  'date': pd.date_range(start='2023-01-01', periods=12, freq='M'),\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# Create sample data\n",
    "def generate_sample_data():\n",
    "    data = {\n",
    "        'date': pd.date_range(start='2023-01-01', periods=12, freq='M'),\n",
    "        'sales': [100, 120, 140, 160, 180, 200, 190, 180, 170, 160, 150, 140]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create visualization\n",
    "def create_sales_plot(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['date'], df['sales'], marker='o')\n",
    "    plt.title('Monthly Sales Trend')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    \n",
    "    return Image.open(buf)\n",
    "\n",
    "# Create messages for analysis workflow\n",
    "df = generate_sample_data()\n",
    "plot_img = AGImage(create_sales_plot(df))\n",
    "\n",
    "# Initial request\n",
    "request_message = TextMessage(\n",
    "    content=\"Let's analyze our monthly sales data for 2023\",\n",
    "    source=\"user\"\n",
    ")\n",
    "\n",
    "# Data summary\n",
    "data_message = TextMessage(\n",
    "    content=f\"Summary Statistics:\\n{df.describe().to_string()}\",\n",
    "    source=\"user\"\n",
    ")\n",
    "\n",
    "# Visualization with analysis\n",
    "visualization_message = MultiModalMessage(\n",
    "    content=[\n",
    "        \"Here's our sales trend visualization. We can observe a peak in June followed by a gradual decline.\",\n",
    "        plot_img\n",
    "    ],\n",
    "    source=\"user\"\n",
    ")\n",
    "\n",
    "# Print messages to verify\n",
    "print(\"Request:\", request_message.content)\n",
    "print(\"\\nData Summary:\", data_message.content)\n",
    "print(\"\\nVisualization Message:\", visualization_message.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32340767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful research assistant with \\\n",
    "        a focus on data analysis and visualization.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "response = await assistant.on_messages([request_message, data_message, visualization_message], cancellation_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb1cc4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sales data for 2023 shows a clear trend:\\n\\n1. **Peak in June**: Sales reached their highest point in June at 200 units.\\n2. **Gradual Decline**: After June, there is a steady decline in sales through the rest of the year.\\n3. **Summary Statistics**:\\n   - **Mean Sales**: 157.5 units\\n   - **Minimum Sales**: 100 units in January\\n   - **Maximum Sales**: 200 units in June\\n   - **Standard Deviation**: 29.27, indicating some variability in sales.\\n\\nThis pattern suggests a strong mid-year performance with a need to investigate the factors contributing to the decline in the latter half of the year. Consider exploring seasonal factors, market changes, or promotional activities that might have influenced these trends.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff308c9",
   "metadata": {},
   "source": [
    "This lesson demonstrated how to work with different types of messages in AutoGen, from simple text communications to complex multimodal interactions and internal events. These message types form the foundation for building sophisticated agent-based systems for data analysis and other applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
