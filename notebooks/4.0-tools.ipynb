{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Use and Function Calling\n",
    "\n",
    "## Empowering Agents with Tools\n",
    "\n",
    "In this notebook, we'll master:\n",
    "\n",
    "1. **Creating Tools**: Building custom tools for agents\n",
    "2. **Async Tools**\n",
    "3. **MCP Tools**\n",
    "4. **Structured Outputs**\n",
    "\n",
    "Tools transform agents from conversational entities into action-oriented problem solvers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import httpx\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# AutoGen imports\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model client\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Tool Creation\n",
    "\n",
    "Let's start with simple tools and understand how they work. \n",
    "\n",
    "[The AssistantAgent automatically converts Python functions into FunctionTool objects, which can be used as a tool by the agent.](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html#using-tools-and-workbench:~:text=Function%20Tool%23,is%20automatically%20generated.) \n",
    "\n",
    "FunctionTool automatically generates the tool schema from the function signature and docstring.\n",
    "\n",
    "below is a simple example where the schema is automatically generated for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'web_search_func',\n",
       " 'description': 'Find information on the web',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'description': 'query',\n",
       "    'title': 'Query',\n",
       "    'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'additionalProperties': False},\n",
       " 'strict': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html#using-tools-and-workbench\n",
    "from autogen_core.tools import FunctionTool\n",
    "\n",
    "\n",
    "# Define a tool using a Python function.\n",
    "async def web_search_func(query: str) -> str:\n",
    "    \"\"\"Find information on the web\"\"\"\n",
    "    return \"AutoGen is a programming framework for building multi-agent applications.\"\n",
    "\n",
    "\n",
    "# This step is automatically performed inside the AssistantAgent if the tool is a Python function.\n",
    "web_search_function_tool = FunctionTool(web_search_func, description=\"Find information on the web\")\n",
    "# The schema is provided to the model during AssistantAgent's on_messages call.\n",
    "web_search_function_tool.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Agent Response:\n",
      "[FunctionCall(id='call_NfAqQLlyC3h8voDhXmLZDlWf', arguments='{\"principal\":10000,\"rate\":7,\"time\":5}', name='calculate_compound_interest')]\n",
      "[FunctionExecutionResult(content=\"{'principal': 10000.0, 'rate': 7.0, 'time': 5, 'final_amount': 14176.25, 'interest_earned': 4176.25}\", name='calculate_compound_interest', call_id='call_NfAqQLlyC3h8voDhXmLZDlWf', is_error=False)]\n",
      "{'principal': 10000.0, 'rate': 7.0, 'time': 5, 'final_amount': 14176.25, 'interest_earned': 4176.25}\n"
     ]
    }
   ],
   "source": [
    "# Simple calculation tools\n",
    "def calculate_compound_interest(\n",
    "    principal: float,\n",
    "    rate: float,\n",
    "    time: int,\n",
    "    compounds_per_year: int = 12\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Calculate compound interest.\n",
    "    \n",
    "    Args:\n",
    "        principal: Initial amount\n",
    "        rate: Annual interest rate (as percentage, e.g., 5 for 5%)\n",
    "        time: Time period in years\n",
    "        compounds_per_year: Number of times interest compounds per year\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with final amount and interest earned\n",
    "    \"\"\"\n",
    "    rate_decimal = rate / 100\n",
    "    amount = principal * (1 + rate_decimal/compounds_per_year) ** (compounds_per_year * time)\n",
    "    interest = amount - principal\n",
    "    \n",
    "    return {\n",
    "        \"principal\": principal,\n",
    "        \"rate\": rate,\n",
    "        \"time\": time,\n",
    "        \"final_amount\": round(amount, 2),\n",
    "        \"interest_earned\": round(interest, 2)\n",
    "    }\n",
    "\n",
    "def convert_currency(\n",
    "    amount: float,\n",
    "    from_currency: str,\n",
    "    to_currency: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Convert currency from one type to another.\n",
    "    \n",
    "    Args:\n",
    "        amount: Amount to convert\n",
    "        from_currency: Source currency code (e.g., 'USD')\n",
    "        to_currency: Target currency code (e.g., 'EUR')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with conversion details\n",
    "    \"\"\"\n",
    "    # Mock exchange rates for demonstration\n",
    "    rates = {\n",
    "        \"USD\": 1.0,\n",
    "        \"EUR\": 0.92,\n",
    "        \"GBP\": 0.79,\n",
    "        \"JPY\": 149.50,\n",
    "        \"CAD\": 1.36,\n",
    "    }\n",
    "    \n",
    "    if from_currency not in rates or to_currency not in rates:\n",
    "        return {\"error\": \"Currency not supported\"}\n",
    "    \n",
    "    # Convert to USD first, then to target currency\n",
    "    usd_amount = amount / rates[from_currency]\n",
    "    converted = usd_amount * rates[to_currency]\n",
    "    \n",
    "    return {\n",
    "        \"original_amount\": amount,\n",
    "        \"from_currency\": from_currency,\n",
    "        \"to_currency\": to_currency,\n",
    "        \"converted_amount\": round(converted, 2),\n",
    "        \"exchange_rate\": round(rates[to_currency] / rates[from_currency], 4)\n",
    "    }\n",
    "\n",
    "# Create an agent with these tools\n",
    "financial_agent = AssistantAgent(\n",
    "    name=\"financial_advisor\",\n",
    "    model_client=model_client,\n",
    "    tools=[calculate_compound_interest, convert_currency],\n",
    "    system_message=\"\"\"You are a financial advisor. Use the available tools to help with financial calculations.\n",
    "    Always explain your calculations clearly.\"\"\",\n",
    ")\n",
    "\n",
    "# Test the agent with tools\n",
    "result = await financial_agent.run(\n",
    "    task=\"I have $10,000. How much will it grow to in 5 years at 7% annual interest? Also, convert the final amount to EUR.\"\n",
    ")\n",
    "\n",
    "print(\"Financial Agent Response:\")\n",
    "for msg in result.messages:\n",
    "    if msg.source == \"financial_advisor\" and msg.content:\n",
    "        print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Async Tools\n",
    "\n",
    "Many real-world tools need to be asynchronous (API calls, database queries, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Analysis:\n",
      "[FunctionCall(id='call_sqZkCx4oImicT0P0dEMVk5HR', arguments='{\"symbol\": \"AAPL\"}', name='fetch_stock_price'), FunctionCall(id='call_tZpnYHve601mSUL2SNTOUdDZ', arguments='{\"symbol\": \"MSFT\"}', name='fetch_stock_price'), FunctionCall(id='call_GXySIGvO7T7gjl2BLsu5WIQ6', arguments='{}', name='analyze_portfolio')]\n",
      "[FunctionExecutionResult(content=\"{'symbol': 'AAPL', 'price': 178.25, 'change': 2.15, 'change_percent': 1.22, 'timestamp': '2025-08-20T16:05:44.883814'}\", name='fetch_stock_price', call_id='call_sqZkCx4oImicT0P0dEMVk5HR', is_error=False), FunctionExecutionResult(content=\"{'symbol': 'MSFT', 'price': 378.5, 'change': 3.2, 'change_percent': 0.85, 'timestamp': '2025-08-20T16:05:44.883934'}\", name='fetch_stock_price', call_id='call_tZpnYHve601mSUL2SNTOUdDZ', is_error=False), FunctionExecutionResult(content='1 validation error for analyze_portfolioargs\\nholdings\\n  Field required [type=missing, input_value={}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing', name='analyze_portfolio', call_id='call_GXySIGvO7T7gjl2BLsu5WIQ6', is_error=True)]\n",
      "{'symbol': 'AAPL', 'price': 178.25, 'change': 2.15, 'change_percent': 1.22, 'timestamp': '2025-08-20T16:05:44.883814'}\n",
      "{'symbol': 'MSFT', 'price': 378.5, 'change': 3.2, 'change_percent': 0.85, 'timestamp': '2025-08-20T16:05:44.883934'}\n",
      "1 validation error for analyze_portfolioargs\n",
      "holdings\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n"
     ]
    }
   ],
   "source": [
    "# Async tool examples\n",
    "async def fetch_stock_price(symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch current stock price (simulated).\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., 'AAPL', 'GOOGL')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with stock information\n",
    "    \"\"\"\n",
    "    # Simulate API delay\n",
    "    await asyncio.sleep(0.5)\n",
    "    \n",
    "    # Mock stock data\n",
    "    stocks = {\n",
    "        \"AAPL\": {\"price\": 178.25, \"change\": 2.15, \"change_percent\": 1.22},\n",
    "        \"GOOGL\": {\"price\": 139.80, \"change\": -0.95, \"change_percent\": -0.67},\n",
    "        \"MSFT\": {\"price\": 378.50, \"change\": 3.20, \"change_percent\": 0.85},\n",
    "        \"AMZN\": {\"price\": 145.60, \"change\": 1.80, \"change_percent\": 1.25},\n",
    "    }\n",
    "    \n",
    "    if symbol.upper() not in stocks:\n",
    "        return {\"error\": f\"Stock symbol {symbol} not found\"}\n",
    "    \n",
    "    data = stocks[symbol.upper()]\n",
    "    return {\n",
    "        \"symbol\": symbol.upper(),\n",
    "        \"price\": data[\"price\"],\n",
    "        \"change\": data[\"change\"],\n",
    "        \"change_percent\": data[\"change_percent\"],\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "async def analyze_portfolio(\n",
    "    holdings: List[Dict[str, Any]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Analyze a stock portfolio.\n",
    "    \n",
    "    Args:\n",
    "        holdings: List of holdings, each with 'symbol' and 'shares'\n",
    "    \n",
    "    Returns:\n",
    "        Portfolio analysis\n",
    "    \"\"\"\n",
    "    total_value = 0\n",
    "    portfolio_details = []\n",
    "    \n",
    "    for holding in holdings:\n",
    "        stock_data = await fetch_stock_price(holding[\"symbol\"])\n",
    "        if \"error\" not in stock_data:\n",
    "            value = stock_data[\"price\"] * holding[\"shares\"]\n",
    "            total_value += value\n",
    "            portfolio_details.append({\n",
    "                \"symbol\": holding[\"symbol\"],\n",
    "                \"shares\": holding[\"shares\"],\n",
    "                \"current_price\": stock_data[\"price\"],\n",
    "                \"value\": round(value, 2),\n",
    "                \"daily_change\": round(stock_data[\"change\"] * holding[\"shares\"], 2)\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"total_value\": round(total_value, 2),\n",
    "        \"holdings\": portfolio_details,\n",
    "        \"analysis_time\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "# Create a stock market agent\n",
    "market_agent = AssistantAgent(\n",
    "    name=\"market_analyst\",\n",
    "    model_client=model_client,\n",
    "    tools=[fetch_stock_price, analyze_portfolio],\n",
    "    system_message=\"\"\"You are a stock market analyst. Use the tools to provide market insights.\n",
    "    Format responses clearly with relevant data.\"\"\",\n",
    ")\n",
    "\n",
    "# Test async tools\n",
    "result = await market_agent.run(\n",
    "    task=\"\"\"Check the current prices of AAPL and MSFT. \n",
    "    Then analyze a portfolio with 100 shares of AAPL and 50 shares of MSFT.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"Market Analysis:\")\n",
    "for msg in result.messages:\n",
    "    if msg.source == \"market_analyst\" and msg.content:\n",
    "        print(msg.content[:1000])  # Truncate for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Context Protocol (MCP) Workbench\n",
    "\n",
    "The AssistantAgent is compatible with mcp (model context protocol) tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle is a major city located in the state of Washington, United States. It was founded on November 13, 1851, and officially incorporated as a town on January 14, 1865, and as a city on December 2, 1869. The city is named after Chief Seattle.\n",
      "\n",
      "Geographically, Seattle covers an area of approximately 142 square miles, with about 84 square miles of land and 58 square miles of water. It sits at an elevation of 148 feet. The city is situated in King County and has a population of around 737,000 as of the 2020 census, with an estimated increase to over 780,000 in 2024. It ranks as the 54th most populous city in North America and 18th in the United States.\n",
      "\n",
      "Seattle is known for landmarks such as the Space Needle, Pike Place Market, and the Amazon Spheres. It is often called \"The Emerald City,\" \"Jet City,\" and \"Rain City.\" The city's government operates under a mayor-council system, with Bruce Harrell serving as mayor. Seattle has a vibrant urban and metropolitan area, with a population of over 4 million in the metro region, and a dense urban environment.\n"
     ]
    }
   ],
   "source": [
    "# source: https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html#using-tools-and-workbench\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n",
    "\n",
    "# Get the fetch tool from mcp-server-fetch.\n",
    "fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])\n",
    "\n",
    "# Create an MCP workbench which provides a session to the mcp server.\n",
    "async with McpWorkbench(fetch_mcp_server) as workbench:  # type: ignore\n",
    "    # Create an agent that can use the fetch tool.\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n",
    "    fetch_agent = AssistantAgent(\n",
    "        name=\"fetcher\", model_client=model_client, workbench=workbench, reflect_on_tool_use=True\n",
    "    )\n",
    "\n",
    "    # Let the agent fetch the content of a URL and summarize it.\n",
    "    result = await fetch_agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\")\n",
    "    assert isinstance(result.messages[-1], TextMessage)\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "    # Close the connection to the model client.\n",
    "    await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the sum of 1 and 2?\n",
      "---------- StructuredMessage[AgentResponse] (assistant) ----------\n",
      "{\"thoughts\":\"This problem is asking for a numerical calculation. Specifically, it's about adding two numbers together. Therefore, this falls under elementary arithmetic, which is a category of mathematics.\",\"response\":\"math\"}\n",
      "Thought:  This problem is asking for a numerical calculation. Specifically, it's about adding two numbers together. Therefore, this falls under elementary arithmetic, which is a category of mathematics.\n",
      "Response:  math\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.messages import StructuredMessage\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "# The response format for the agent as a Pydantic base model.\n",
    "class AgentResponse(BaseModel):\n",
    "    thoughts: str\n",
    "    response: Literal[\"math\", \"coding\", \"other\"]\n",
    "\n",
    "\n",
    "# Create an agent that uses the OpenAI GPT-4o model.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "agent = AssistantAgent(\n",
    "    \"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Categorize the problems given by the user as: math, coding, other.\",\n",
    "    # Define the output content type of the agent.\n",
    "    output_content_type=AgentResponse,\n",
    ")\n",
    "\n",
    "result = await Console(agent.run_stream(task=\"What is the sum of 1 and 2?\"))\n",
    "\n",
    "# Check the last message in the result, validate its type, and print the thoughts and response.\n",
    "assert isinstance(result.messages[-1], StructuredMessage)\n",
    "assert isinstance(result.messages[-1].content, AgentResponse)\n",
    "print(\"Thought: \", result.messages[-1].content.thoughts)\n",
    "print(\"Response: \", result.messages[-1].content.response)\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "I love teaching people about agents!\n",
      "---------- StructuredMessage[AgentResponse] (assistant) ----------\n",
      "{\"thoughts\":\"The sentence expresses a positive emotion towards teaching people about agents.\",\"response\":\"positive\"}\n",
      "Thought:  The sentence expresses a positive emotion towards teaching people about agents.\n",
      "Response:  positive\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.messages import StructuredMessage\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "# The response format for the agent as a Pydantic base model.\n",
    "class AgentResponse(BaseModel):\n",
    "    thoughts: str\n",
    "    response: Literal[\"negative\", \"positive\", \"neutral\"]\n",
    "\n",
    "\n",
    "# Create an agent that uses the OpenAI GPT-4o model.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "agent = AssistantAgent(\n",
    "    \"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Categorize the sentences as: negative, positive, neutral.\",\n",
    "    # Define the output content type of the agent.\n",
    "    output_content_type=AgentResponse,\n",
    ")\n",
    "\n",
    "result = await Console(agent.run_stream(task=\"I love teaching people about agents!\"))\n",
    "\n",
    "# Check the last message in the result, validate its type, and print the thoughts and response.\n",
    "assert isinstance(result.messages[-1], StructuredMessage)\n",
    "assert isinstance(result.messages[-1].content, AgentResponse)\n",
    "print(\"Thought: \", result.messages[-1].content.thoughts)\n",
    "print(\"Response: \", result.messages[-1].content.response)\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agents as Tools\n",
    "\n",
    "You can also use agents themselves as tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_summarize = \"\"\"\n",
    "'Modern LLM agents are goal-directed systems built around large language models that can plan and act, \n",
    "not just chat. They interact with external tools, services, and environments to achieve outcomes, \n",
    "iterating through a loop of observing context, planning next steps, taking actions, and using the \n",
    "results to refine their approach. Architecturally, they pair an LLM with a function-calling layer for \n",
    "tools and APIs, a memory or state store, and policies that constrain behavior. This enables multi-step \n",
    "workflows such as analyzing datasets, booking travel, triaging support tickets, or orchestrating business \n",
    "processes end to end.\\n\\nTo stay grounded, agents often augment the model with retrieval so it can consult \n",
    "documents, knowledge bases, or the web before answering. Tool use spans calling APIs and databases, browsing, \n",
    "and writing or executing code in a sandbox to transform data or validate results. Many implementations \n",
    "decompose tasks into subgoals, track intermediate state, and emit structured outputs for downstream systems. \n",
    "Orchestrators can coordinate multiple specialized agents (for example, researcher, coder, tester) and hand \n",
    "off work, while guardrails enforce schemas, permissions, and organizational policies. Integration is \n",
    "typically done through structured function calls, JSON schemas, and event-driven workflows.\\n\\nDespite \n",
    "their versatility, LLM agents have limits: they can hallucinate, mishandle edge cases, and struggle with \n",
    "very long-horizon plans or ambiguous goals. Practical deployments rely on safeguards such as permissioning, \n",
    "human-in-the-loop review, sandboxed tool execution, rate limits, and continuous evaluation of task success \n",
    "and safety. Cost and latency are important, so designers cache results, reuse context, and adapt model size \n",
    "to task complexity. Good applications align with agent strengths—information synthesis, routine workflow \n",
    "automation, data wrangling, and software assistance—while avoiding high-stakes decisions without oversight. \n",
    "Looking ahead, better memory, more reliable planning, and tighter integration with enterprise systems and \n",
    "hardware will make agents more capable and trustworthy.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "\n",
      "                                   Summarize this: \n",
      "                                   \n",
      "'Modern LLM agents are goal-directed systems built around large language models that can plan and act, \n",
      "not just chat. They interact with external tools, services, and environments to achieve outcomes, \n",
      "iterating through a loop of observing context, planning next steps, taking actions, and using the \n",
      "results to refine their approach. Architecturally, they pair an LLM with a function-calling layer for \n",
      "tools and APIs, a memory or state store, and policies that constrain behavior. This enables multi-step \n",
      "workflows such as analyzing datasets, booking travel, triaging support tickets, or orchestrating business \n",
      "processes end to end.\n",
      "\n",
      "To stay grounded, agents often augment the model with retrieval so it can consult \n",
      "documents, knowledge bases, or the web before answering. Tool use spans calling APIs and databases, browsing, \n",
      "and writing or executing code in a sandbox to transform data or validate results. Many implementations \n",
      "decompose tasks into subgoals, track intermediate state, and emit structured outputs for downstream systems. \n",
      "Orchestrators can coordinate multiple specialized agents (for example, researcher, coder, tester) and hand \n",
      "off work, while guardrails enforce schemas, permissions, and organizational policies. Integration is \n",
      "typically done through structured function calls, JSON schemas, and event-driven workflows.\n",
      "\n",
      "Despite \n",
      "their versatility, LLM agents have limits: they can hallucinate, mishandle edge cases, and struggle with \n",
      "very long-horizon plans or ambiguous goals. Practical deployments rely on safeguards such as permissioning, \n",
      "human-in-the-loop review, sandboxed tool execution, rate limits, and continuous evaluation of task success \n",
      "and safety. Cost and latency are important, so designers cache results, reuse context, and adapt model size \n",
      "to task complexity. Good applications align with agent strengths—information synthesis, routine workflow \n",
      "automation, data wrangling, and software assistance—while avoiding high-stakes decisions without oversight. \n",
      "Looking ahead, better memory, more reliable planning, and tighter integration with enterprise systems and \n",
      "hardware will make agents more capable and trustworthy.'\n",
      "\n",
      "                                   \n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='call_ncOXmapqnmWj1DITJXL8IUPy', arguments='{\"task\":\"Summarize the provided passage about modern LLM agents, focusing on their architecture, capabilities, use cases, limitations, and future improvements.\"}', name='summarizer')]\n",
      "---------- TextMessage (user) ----------\n",
      "Summarize the provided passage about modern LLM agents, focusing on their architecture, capabilities, use cases, limitations, and future improvements.\n",
      "---------- TextMessage (summarizer) ----------\n",
      "Certainly! Please provide the passage you'd like summarized.\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content=\"summarizer: Certainly! Please provide the passage you'd like summarized.\", name='summarizer', call_id='call_ncOXmapqnmWj1DITJXL8IUPy', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (assistant) ----------\n",
      "summarizer: Certainly! Please provide the passage you'd like summarized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='80a3a530-3c31-43ec-abc4-974a843bf726', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 38, 807484, tzinfo=datetime.timezone.utc), content=\"\\n                                   Summarize this: \\n                                   \\n'Modern LLM agents are goal-directed systems built around large language models that can plan and act, \\nnot just chat. They interact with external tools, services, and environments to achieve outcomes, \\niterating through a loop of observing context, planning next steps, taking actions, and using the \\nresults to refine their approach. Architecturally, they pair an LLM with a function-calling layer for \\ntools and APIs, a memory or state store, and policies that constrain behavior. This enables multi-step \\nworkflows such as analyzing datasets, booking travel, triaging support tickets, or orchestrating business \\nprocesses end to end.\\n\\nTo stay grounded, agents often augment the model with retrieval so it can consult \\ndocuments, knowledge bases, or the web before answering. Tool use spans calling APIs and databases, browsing, \\nand writing or executing code in a sandbox to transform data or validate results. Many implementations \\ndecompose tasks into subgoals, track intermediate state, and emit structured outputs for downstream systems. \\nOrchestrators can coordinate multiple specialized agents (for example, researcher, coder, tester) and hand \\noff work, while guardrails enforce schemas, permissions, and organizational policies. Integration is \\ntypically done through structured function calls, JSON schemas, and event-driven workflows.\\n\\nDespite \\ntheir versatility, LLM agents have limits: they can hallucinate, mishandle edge cases, and struggle with \\nvery long-horizon plans or ambiguous goals. Practical deployments rely on safeguards such as permissioning, \\nhuman-in-the-loop review, sandboxed tool execution, rate limits, and continuous evaluation of task success \\nand safety. Cost and latency are important, so designers cache results, reuse context, and adapt model size \\nto task complexity. Good applications align with agent strengths—information synthesis, routine workflow \\nautomation, data wrangling, and software assistance—while avoiding high-stakes decisions without oversight. \\nLooking ahead, better memory, more reliable planning, and tighter integration with enterprise systems and \\nhardware will make agents more capable and trustworthy.'\\n\\n                                   \", type='TextMessage'), ToolCallRequestEvent(id='65edf002-d80a-408f-9046-91f45cbf18ee', source='assistant', models_usage=RequestUsage(prompt_tokens=492, completion_tokens=42), metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 40, 809479, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='call_ncOXmapqnmWj1DITJXL8IUPy', arguments='{\"task\":\"Summarize the provided passage about modern LLM agents, focusing on their architecture, capabilities, use cases, limitations, and future improvements.\"}', name='summarizer')], type='ToolCallRequestEvent'), TextMessage(id='f473ce4b-6288-4018-ac68-11053c6e6e93', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 40, 811121, tzinfo=datetime.timezone.utc), content='Summarize the provided passage about modern LLM agents, focusing on their architecture, capabilities, use cases, limitations, and future improvements.', type='TextMessage'), TextMessage(id='cb8abaa0-e914-47a3-a568-8199283e96f6', source='summarizer', models_usage=RequestUsage(prompt_tokens=43, completion_tokens=10), metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 42, 732469, tzinfo=datetime.timezone.utc), content=\"Certainly! Please provide the passage you'd like summarized.\", type='TextMessage'), ToolCallExecutionEvent(id='4da924a3-380c-476d-80c0-835212d1dcd0', source='assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 42, 736345, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content=\"summarizer: Certainly! Please provide the passage you'd like summarized.\", name='summarizer', call_id='call_ncOXmapqnmWj1DITJXL8IUPy', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(id='7ae2896e-a3b0-4927-afbc-744e21d96438', source='assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 15, 19, 42, 738456, tzinfo=datetime.timezone.utc), content=\"summarizer: Certainly! Please provide the passage you'd like summarized.\", type='ToolCallSummaryMessage', tool_calls=[FunctionCall(id='call_ncOXmapqnmWj1DITJXL8IUPy', arguments='{\"task\":\"Summarize the provided passage about modern LLM agents, focusing on their architecture, capabilities, use cases, limitations, and future improvements.\"}', name='summarizer')], results=[FunctionExecutionResult(content=\"summarizer: Certainly! Please provide the passage you'd like summarized.\", name='summarizer', call_id='call_ncOXmapqnmWj1DITJXL8IUPy', is_error=False)])], stop_reason=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html#autogen_agentchat.tools.AgentTool\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.tools import AgentTool\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n",
    "writer = AssistantAgent(\n",
    "    name=\"summarizer\",\n",
    "    description=\"You take in text and you summarize.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Write well.\",\n",
    ")\n",
    "summarizer_tool = AgentTool(agent=writer)\n",
    "\n",
    "# Create model client with parallel tool calls disabled for the main agent\n",
    "main_model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\", parallel_tool_calls=False)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=main_model_client,\n",
    "    tools=[summarizer_tool],\n",
    "    system_message=\"You are a helpful assistant. When requested to summarize information, use the summarizer tool.\",\n",
    ")\n",
    "await Console(assistant.run_stream(task=f\"\"\"\n",
    "                                   Summarize this: \n",
    "                                   {content_to_summarize}\n",
    "                                   \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Analysis:\n",
      "[FunctionCall(id='call_JCt3TSziUpciiUpz27gqaMqY', arguments='{\"url\": \"https://github.com/microsoft/autogen\", \"extract_type\": \"summary\"}', name='analyze_webpage'), FunctionCall(id='call_TDuYfp6hkqwtFumQsqxyia2O', arguments='{\"url\": \"https://github.com/microsoft/autogen\", \"extract_type\": \"metadata\"}', name='analyze_webpage'), FunctionCall(id='call_7Ta9HoDZGwel919djanhfO85', arguments='{\"url\": \"https://github.com/langchain-ai/langchain\", \"extract_type\": \"summary\"}', name='analyze_webpage'), FunctionCall(id='call_qTzFzbY2WCXfYN2qefEemI7z', arguments='{\"url\": \"https://github.com/langchain-ai/langchain\", \"extract_type\": \"metadata\"}', name='analyze_webpage')]\n",
      "[FunctionExecutionResult(content=\"{'url': 'https://github.com/microsoft/autogen', 'title': 'AutoGen - Multi-agent Framework', 'summary': 'A framework for building multi-agent AI applications', 'main_topics': ['AI agents', 'LLM integration', 'Tool use'], 'word_count': 1250}\", name='analyze_webpage', call_id='call_JCt3TSziUpciiUpz27gqaMqY', is_error=False), FunctionExecutionResult(content=\"{'url': 'https://github.com/microsoft/autogen', 'last_updated': '2024-01-15', 'language': 'en', 'technologies': ['Python', 'TypeScript'], 'license': 'MIT'}\", name='analyze_webpage', call_id='call_TDuYfp6hkqwtFumQsqxyia2O', is_error=False), FunctionExecutionResult(content=\"{'url': 'https://github.com/langchain-ai/langchain', 'title': 'AutoGen - Multi-agent Framework', 'summary': 'A framework for building multi-agent AI applications', 'main_topics': ['AI agents', 'LLM integration', 'Tool use'], 'word_count': 1250}\", name='analyze_webpage', call_id='call_7Ta9HoDZGwel919djanhfO85', is_error=False), FunctionExecutionResult(content=\"{'url': 'https://github.com/langchain-ai/langchain', 'last_updated': '2024-01-15', 'language': 'en', 'technologies': ['Python', 'TypeScript'], 'license': 'MIT'}\", name='analyze_webpage', call_id='call_qTzFzbY2WCXfYN2qefEemI7z', is_error=False)]\n",
      "{'url': 'https://github.com/microsoft/autogen', 'title': 'AutoGen - Multi-agent Framework', 'summary': 'A framework for building multi-agent AI applications', 'main_topics': ['AI agents', 'LLM integration', 'Tool use'], 'word_count': 1250}\n",
      "{'url': 'https://github.com/microsoft/autogen', 'last_updated': '2024-01-15', 'language': 'en', 'technologies': ['Python', 'TypeScript'], 'license': 'MIT'}\n",
      "{'url': 'https://github.com/langchain-ai/langchain', 'title': 'AutoGen - Multi-agent Framework', 'summary': 'A framework for building multi-agent AI applications', 'main_topics': ['AI agents', 'LLM integration', 'Tool use'], 'word_count': 1250}\n",
      "{'url': 'https://github.com/langchain-ai/langchain', 'last_updated': '2024-01-15', 'language': 'en', 'technologies': ['Python', 'TypeScript'], 'license': 'MIT'}\n"
     ]
    }
   ],
   "source": [
    "# Complex tool combining multiple operations\n",
    "async def analyze_webpage(\n",
    "    url: str,\n",
    "    extract_type: str = \"summary\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Analyze a webpage and extract information.\n",
    "    \n",
    "    Args:\n",
    "        url: URL to analyze\n",
    "        extract_type: Type of extraction ('summary', 'links', 'metadata')\n",
    "    \n",
    "    Returns:\n",
    "        Extracted information\n",
    "    \"\"\"\n",
    "    # Simulate web scraping\n",
    "    await asyncio.sleep(0.5)\n",
    "    \n",
    "    # Mock data based on URL\n",
    "    if \"github.com\" in url:\n",
    "        if extract_type == \"summary\":\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"title\": \"AutoGen - Multi-agent Framework\",\n",
    "                \"summary\": \"A framework for building multi-agent AI applications\",\n",
    "                \"main_topics\": [\"AI agents\", \"LLM integration\", \"Tool use\"],\n",
    "                \"word_count\": 1250\n",
    "            }\n",
    "        elif extract_type == \"links\":\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"total_links\": 42,\n",
    "                \"internal_links\": 28,\n",
    "                \"external_links\": 14,\n",
    "                \"top_domains\": [\"github.com\", \"microsoft.com\", \"openai.com\"]\n",
    "            }\n",
    "        elif extract_type == \"metadata\":\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"last_updated\": \"2024-01-15\",\n",
    "                \"language\": \"en\",\n",
    "                \"technologies\": [\"Python\", \"TypeScript\"],\n",
    "                \"license\": \"MIT\"\n",
    "            }\n",
    "    \n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"error\": \"Could not analyze webpage\"\n",
    "    }\n",
    "\n",
    "def compare_webpages(\n",
    "    page1_data: Dict[str, Any],\n",
    "    page2_data: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Compare data from two webpages.\n",
    "    \n",
    "    Args:\n",
    "        page1_data: Data from first webpage\n",
    "        page2_data: Data from second webpage\n",
    "    \n",
    "    Returns:\n",
    "        Comparison results\n",
    "    \"\"\"\n",
    "    comparison = {\n",
    "        \"pages_compared\": [page1_data.get(\"url\"), page2_data.get(\"url\")],\n",
    "        \"similarities\": [],\n",
    "        \"differences\": []\n",
    "    }\n",
    "    \n",
    "    # Find common keys\n",
    "    common_keys = set(page1_data.keys()) & set(page2_data.keys())\n",
    "    \n",
    "    for key in common_keys:\n",
    "        if page1_data[key] == page2_data[key]:\n",
    "            comparison[\"similarities\"].append({\n",
    "                \"field\": key,\n",
    "                \"value\": page1_data[key]\n",
    "            })\n",
    "        else:\n",
    "            comparison[\"differences\"].append({\n",
    "                \"field\": key,\n",
    "                \"page1\": page1_data[key],\n",
    "                \"page2\": page2_data[key]\n",
    "            })\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Create a web analyst agent\n",
    "web_agent = AssistantAgent(\n",
    "    name=\"web_analyst\",\n",
    "    model_client=model_client,\n",
    "    tools=[analyze_webpage, compare_webpages],\n",
    "    system_message=\"\"\"You are a web analyst. Use the tools to analyze and compare webpages.\n",
    "    Provide insights based on the extracted data.\"\"\",\n",
    ")\n",
    "\n",
    "# Test complex tool usage\n",
    "result = await web_agent.run(\n",
    "    task=\"\"\"Analyze https://github.com/microsoft/autogen - extract both summary and metadata.\n",
    "    Then analyze https://github.com/langchain-ai/langchain and compare the two pages.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"Web Analysis:\")\n",
    "for msg in result.messages:\n",
    "    if msg.source == \"web_analyst\" and msg.content:\n",
    "        print(msg.content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model client closed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Close the model client\n",
    "await model_client.close()\n",
    "print(\"Model client closed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook, you learned how to empower agents with tools using the AutoGen framework:\n",
    "\n",
    "\n",
    "1. ✅ **Creating Tools**: How to define both synchronous and asynchronous Python functions as tools for agents.\n",
    "2. ✅ **Async Tools**: How to create async tools\n",
    "3. ✅ **MCP Tools**: How to create mcp compatible tools\n",
    "4. ✅ **Structured Outputs**: How to get structured outputs from agents\n",
    "5. ✅ **Agents as Tools**: How to convert agents into tools for other agents\n",
    "\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Tools extend agent capabilities**: By registering Python functions or even other agents as tools, you enable agents to take real actions and solve practical problems.\n",
    "- **Type hints and docstrings matter**: They drive schema generation and improve tool usability for LLMs.\n",
    "- **Async support is essential**: Many real-world tools (APIs, I/O) are asynchronous—AutoGen supports both sync and async tools.\n",
    "- **Leverage MCP for a more robust system**\n",
    "- **Leverage agents as tools and structured outputs to create controllable agentic workflows**\n",
    "\n",
    "# Exercises\n",
    "\n",
    "1. **Exercise 1**: Create a tool that calls a real external API (e.g., weather, news, or finance).\n",
    "2. **Exercise 2**: Implement an agent as a tool for a financial data analysis scenario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
