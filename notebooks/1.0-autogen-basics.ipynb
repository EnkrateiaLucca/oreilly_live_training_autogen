{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-core\"\n",
    "%pip install -U \"autogen-agentchat\"\n",
    "%pip install \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async environment configured for Jupyter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    print(\"Async environment configured for Jupyter.\")\n",
    "except ImportError:\n",
    "    print(\"Please install nest_asyncio with `pip install nest_asyncio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "import os\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=21), content='Welcome to this Course about Autogen! How can I assist you today in learning about AI agents?', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant that helps students \\\n",
    "            understand how to build AI Agents! You always greet students \\\n",
    "                by saing 'Welcome to this Course about Autogen!'\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    response = await assistant.on_messages([TextMessage(content=\"Hello!\", source=\"user\")], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "# This allows running async code in Jupyter\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=1172, completion_tokens=104), content='The image shows a code snippet in a programming environment. It appears to be Python code, importing various modules and defining an asynchronous function `main()`. The function initializes a `model_client` using `OpenAIChatCompletionClient` with parameters like `model=\"gpt-4o\"`, `seed=42`, and `temperature`. An `AssistantAgent` is also being created with the name \"assistant\". The terminal at the bottom shows the directory path `~/Desktop/projects/learning/autogen-stuff`.', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken, Image\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    message = MultiModalMessage(\n",
    "        content=[\"Here is an image:\", Image.from_file(Path(\"test.png\"))],\n",
    "        source=\"user\",\n",
    "    )\n",
    "    response = await assistant.on_messages([message], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def fetch_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "# Initialize the agent\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You return weather information given a city name using the fetch_weather tool.\",\n",
    "    tools=[fetch_weather], # Register the tool function\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "output = await assistant.on_messages([TextMessage(content=\"What is the weather in San Francisco?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_g7pkSkwGDQxMviJLarrSclFK', arguments='{\"city\":\"San Francisco\"}', name='fetch_weather')]\n",
      "[FunctionExecutionResult(content='The weather in San Francisco is sunny.', call_id='call_g7pkSkwGDQxMviJLarrSclFK')]\n"
     ]
    }
   ],
   "source": [
    "for msg in output.inner_messages:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is sunny.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
