{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autogen AgentChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-core\"\n",
    "%pip install -U \"autogen-agentchat\"\n",
    "%pip install \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async environment configured for Jupyter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    print(\"Async environment configured for Jupyter.\")\n",
    "except ImportError:\n",
    "    print(\"Please install nest_asyncio with `pip install nest_asyncio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "import os\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=21), content='Welcome to this Course about Autogen! How can I assist you today in learning about AI agents?', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant that helps students \\\n",
    "            understand how to build AI Agents! You always greet students \\\n",
    "                by saing 'Welcome to this Course about Autogen!'\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    response = await assistant.on_messages([TextMessage(content=\"Hello!\", source=\"user\")], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "# This allows running async code in Jupyter\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", seed=42, temperature=0)\n",
    "\n",
    "assistant_helper = AssistantAgent(\n",
    "    name=\"assistant_helper2\",\n",
    "    system_message = \"You are a helpful assistant\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "cancellation_token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant_helper2', models_usage=RequestUsage(prompt_tokens=19, completion_tokens=10), content='Hello! How can I assist you today?', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "async def run_my_assistant():\n",
    "    response = await assistant_helper.on_messages([TextMessage(content=\"Hello!\", source=\"user\")], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "asyncio.run(run_my_assistant())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=891, completion_tokens=81), content='The image is a webpage for \"AgentChat,\" a high-level API for building multi-agent applications. It is built on top of the `autogen-core` package. The page highlights features like intuitive defaults, agents with preset behaviors, and teams with predefined multi-agent design patterns. It includes sections for Installation, Quickstart, Tutorial, and Selector Group Chat, each offering guidance on using AgentChat.', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken, Image\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    message = MultiModalMessage(\n",
    "        content=[\"Here is an image:\", Image.from_file(Path(\"test.png\"))],\n",
    "        source=\"user\",\n",
    "    )\n",
    "    response = await assistant.on_messages([message], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def fetch_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "# Initialize the agent\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You return weather information given a city name using the fetch_weather tool.\",\n",
    "    tools=[fetch_weather], # Register the tool function\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "output = await assistant.on_messages([TextMessage(content=\"What is the weather in San Francisco?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_xncCDqs7ZHUp24YdaTGqEsjT', arguments='{\"city\":\"San Francisco\"}', name='fetch_weather')]\n",
      "[FunctionExecutionResult(content='The weather in San Francisco is sunny.', call_id='call_xncCDqs7ZHUp24YdaTGqEsjT')]\n"
     ]
    }
   ],
   "source": [
    "for msg in output.inner_messages:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is sunny.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "\n",
    "\n",
    "#!pip install yfinance matplotlib pytz numpy pandas python-dotenv requests bs4\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    search_engine_id = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": str(api_key), \"cx\": str(search_engine_id), \"q\": str(query), \"num\": str(num_results)}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results\n",
    "\n",
    "search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    tools=[search_tool],\n",
    "    description=\"Search Google for information, returns top 5 results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await search_agent.on_messages([TextMessage(content=\"How to set up custom tools in Autogen Agentchat version 0.4.1?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'title': 'microsoft/autogen: A programming framework for agentic AI ... - GitHub', 'link': 'https://github.com/microsoft/autogen', 'snippet': '# pip install -U autogen-agentchat autogen-ext[openai,web-surfer] # playwright install ... You can use the AutoGen framework and developer tools to create\\\\xa0...', 'body': 'GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code'}, {'title': 'AutoGen', 'link': 'https://www.reddit.com/r/AutoGenAI/', 'snippet': 'Sep 27, 2023 ... Improved component config by allowing subclassing the BaseComponent class. #5017. To read more about how to create your own component config to\\\\xa0...', 'body': 'Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising. By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper'}, {'title': 'Literature Review â€” AutoGen', 'link': 'https://microsoft.github.io/autogen/dev//user-guide/agentchat-user-guide/examples/literature-review.html', 'snippet': 'Note: You will need to set the appropriate environment variables for tools as needed. Also install required libraries: !pip install arxiv.', 'body': 'Literature Review â€” AutoGen Skip to main content Back to top Ctrl + K AgentChat Core Extensions Studio API Reference 0.2 Docs GitHub Discord Twitter AgentChat Core Extensions Studio API Reference 0.2 Docs GitHub Discord Twitter Installation Quickstart Migration Guide for v0.2 to v0.4 Tutorial Introduction Models Messages Agents Teams Human-in-the-Loop Termination Custom Agents Managing State Declarative Components Memory Advanced Selector Group Chat Swarm Magentic-One More Examples Travel'}, {'title': 'autogen-watsonx-client Â· PyPI', 'link': 'https://pypi.org/project/autogen-watsonx-client/0.0.5/', 'snippet': 'pip install --upgrade autogen-agentchat>=0.4.1; access to a watsonx.ai instance, setting up ... tools=[get_weather], ) # Define termination condition\\\\xa0...', 'body': 'JavaScript is disabled in your browser. Please enable JavaScript to proceed. A required part of this site couldnâ€™t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.'}, {'title': 'An objective comparison of LLM Agents | by RUiNtheExtinct | Medium', 'link': 'https://ruintheextinct.medium.com/an-objective-comparison-of-llm-agents-1584acfd2682', 'snippet': 'Nov 5, 2023 ... ... AutoGen is that it supports multi-agent chat and collaboration. So we can create different agents, each with their own roles and set of tools.', 'body': 'An objective comparison of LLM Agents | by RUiNtheExtinct | Medium Open in app Sign up Sign in Write Sign up Sign in An objective comparison of LLM Agents RUiNtheExtinct Â· Follow 10 min read Â· Nov 5, 2023 -- 1 Listen Share There are quite a few LLM agents available today. Some of the most prominent ones are AutoGPT, AutoGen, BabyAGI, and OpenAgents. This article aims to provide a side-by-side comparison of those models and in which use cases we should and should not use them. AutoGen AutoGen is'}]\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "results = literal_eval(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'microsoft/autogen: A programming framework for agentic AI ... - GitHub',\n",
       "  'link': 'https://github.com/microsoft/autogen',\n",
       "  'snippet': '# pip install -U autogen-agentchat autogen-ext[openai,web-surfer] # playwright install ... You can use the AutoGen framework and developer tools to create\\xa0...',\n",
       "  'body': 'GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code'},\n",
       " {'title': 'AutoGen',\n",
       "  'link': 'https://www.reddit.com/r/AutoGenAI/',\n",
       "  'snippet': 'Sep 27, 2023 ... Improved component config by allowing subclassing the BaseComponent class. #5017. To read more about how to create your own component config to\\xa0...',\n",
       "  'body': 'Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising. By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper'},\n",
       " {'title': 'Literature Review â€” AutoGen',\n",
       "  'link': 'https://microsoft.github.io/autogen/dev//user-guide/agentchat-user-guide/examples/literature-review.html',\n",
       "  'snippet': 'Note: You will need to set the appropriate environment variables for tools as needed. Also install required libraries: !pip install arxiv.',\n",
       "  'body': 'Literature Review â€” AutoGen Skip to main content Back to top Ctrl + K AgentChat Core Extensions Studio API Reference 0.2 Docs GitHub Discord Twitter AgentChat Core Extensions Studio API Reference 0.2 Docs GitHub Discord Twitter Installation Quickstart Migration Guide for v0.2 to v0.4 Tutorial Introduction Models Messages Agents Teams Human-in-the-Loop Termination Custom Agents Managing State Declarative Components Memory Advanced Selector Group Chat Swarm Magentic-One More Examples Travel'},\n",
       " {'title': 'autogen-watsonx-client Â· PyPI',\n",
       "  'link': 'https://pypi.org/project/autogen-watsonx-client/0.0.5/',\n",
       "  'snippet': 'pip install --upgrade autogen-agentchat>=0.4.1; access to a watsonx.ai instance, setting up ... tools=[get_weather], ) # Define termination condition\\xa0...',\n",
       "  'body': 'JavaScript is disabled in your browser. Please enable JavaScript to proceed. A required part of this site couldnâ€™t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.'},\n",
       " {'title': 'An objective comparison of LLM Agents | by RUiNtheExtinct | Medium',\n",
       "  'link': 'https://ruintheextinct.medium.com/an-objective-comparison-of-llm-agents-1584acfd2682',\n",
       "  'snippet': 'Nov 5, 2023 ... ... AutoGen is that it supports multi-agent chat and collaboration. So we can create different agents, each with their own roles and set of tools.',\n",
       "  'body': 'An objective comparison of LLM Agents | by RUiNtheExtinct | Medium Open in app Sign up Sign in Write Sign up Sign in An objective comparison of LLM Agents RUiNtheExtinct Â· Follow 10 min read Â· Nov 5, 2023 -- 1 Listen Share There are quite a few LLM agents available today. Some of the most prominent ones are AutoGPT, AutoGen, BabyAGI, and OpenAgents. This article aims to provide a side-by-side comparison of those models and in which use cases we should and should not use them. AutoGen AutoGen is'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: microsoft/autogen: A programming framework for agentic AI ... - GitHub\n",
      "Link: https://github.com/microsoft/autogen\n",
      "Snippet: # pip install -U autogen-agentchat autogen-ext[openai,web-surfer] # playwright install ... You can use the AutoGen framework and developer tools to createÂ ...\n",
      "Body: GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navi...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: AutoGen\n",
      "Link: https://www.reddit.com/r/AutoGenAI/\n",
      "Snippet: Sep 27, 2023 ... Improved component config by allowing subclassing the BaseComponent class. #5017. To read more about how to create your own component config toÂ ...\n",
      "Body: Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, y...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Literature Review â€” AutoGen\n",
      "Link: https://microsoft.github.io/autogen/dev//user-guide/agentchat-user-guide/examples/literature-review.html\n",
      "Snippet: Note: You will need to set the appropriate environment variables for tools as needed. Also install required libraries: !pip install arxiv.\n",
      "Body: Literature Review â€” AutoGen Skip to main content Back to top Ctrl + K AgentChat Core Extensions Studio API Reference 0.2 Docs GitHub Discord Twitter AgentChat Core Extensions Studio API Reference 0.2 ...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: autogen-watsonx-client Â· PyPI\n",
      "Link: https://pypi.org/project/autogen-watsonx-client/0.0.5/\n",
      "Snippet: pip install --upgrade autogen-agentchat>=0.4.1; access to a watsonx.ai instance, setting up ... tools=[get_weather], ) # Define termination conditionÂ ...\n",
      "Body: JavaScript is disabled in your browser. Please enable JavaScript to proceed. A required part of this site couldnâ€™t load. This may be due to a browser extension, network issues, or browser settings. Pl...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: An objective comparison of LLM Agents | by RUiNtheExtinct | Medium\n",
      "Link: https://ruintheextinct.medium.com/an-objective-comparison-of-llm-agents-1584acfd2682\n",
      "Snippet: Nov 5, 2023 ... ... AutoGen is that it supports multi-agent chat and collaboration. So we can create different agents, each with their own roles and set of tools.\n",
      "Body: An objective comparison of LLM Agents | by RUiNtheExtinct | Medium Open in app Sign up Sign in Write Sign up Sign in An objective comparison of LLM Agents RUiNtheExtinct Â· Follow 10 min read Â· Nov 5, ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loop through and print each result nicely formatted\n",
    "for result in results:\n",
    "    print(\"Title:\", result['title'])\n",
    "    print(\"Link:\", result['link'])\n",
    "    print(\"Snippet:\", result['snippet'])\n",
    "    print(\"Body:\", result['body'][:200] + \"...\")  # Print first 200 chars of body\n",
    "    print(\"-\" * 80)  # Print separator line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancellation tokenn is something you use to cancell the async calls during an agent's execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Cancellation Token?\n",
    "\n",
    "Token to cancel pending async calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation was cancelled.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main():\n",
    "    # Initialize the model client\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "\n",
    "    # Create an instance of AssistantAgent\n",
    "    agent = AssistantAgent(name=\"assistant\", model_client=model_client)\n",
    "\n",
    "    # Create a cancellation token\n",
    "    cancellation_token = CancellationToken()\n",
    "\n",
    "    try:\n",
    "        # Start a task that will cancel the token after 5 seconds\n",
    "        asyncio.create_task(cancel_after_delay(cancellation_token, 3))\n",
    "\n",
    "        # Send a message to the agent with the cancellation token\n",
    "        response = await agent.on_messages(\n",
    "            [TextMessage(content=\"Write me a story about the history of Large Language Models\", source=\"user\")],\n",
    "            cancellation_token=cancellation_token,\n",
    "        )\n",
    "        print(response.chat_message.content)\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"The operation was cancelled.\")\n",
    "\n",
    "async def cancel_after_delay(cancellation_token, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    cancellation_token.cancel()\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancellation tokenn is something you use to cancell the async calls during an agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
