{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with AutoGen\n",
    "\n",
    "## Welcome to AutoGen!\n",
    "\n",
    "AutoGen is a programming framework for building multi-agent AI applications. In this quickstart notebook, we'll:\n",
    "\n",
    "1. Install AutoGen\n",
    "2. Create your first agent\n",
    "3. Build a simple two-agent conversation\n",
    "4. Add tools and function calling\n",
    "5. Stream agent responses\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGen AgentChat and Extensions\n",
    "!pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up API Keys\n",
    "\n",
    "AutoGen works with various LLM providers. For this tutorial, we'll use OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your OpenAI API key\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Your First Agent\n",
    "\n",
    "Let's create a simple assistant agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize the model client\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ[\"OPENAI_API_KEY\"],  # Optional, will use env var\n",
    ")\n",
    "\n",
    "# Create an assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant. Be concise and informative.\",\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Your First Agent Task\n",
    "\n",
    "Now let's run a simple task with our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "--------------------------------------------------\n",
      "user: What is a large language model?\n",
      "helpful_assistant: A large language model (LLM) is a type of artificial intelligence model designed to understand, generate, and manipulate human language. LLMs are typically based on deep learning architectures, particularly transformer networks. They are trained on vast datasets containing text from books, websites, and other written sources, allowing them to learn patterns, grammar, and contextual relationships in language.\n",
      "\n",
      "Key characteristics of LLMs include:\n",
      "\n",
      "1. **Size**: They have millions to billions of parameters, which are the variables that the model learns from the training data.\n",
      "2. **Contextual Understanding**: LLMs can understand context, allowing them to produce coherent and relevant responses.\n",
      "3. **Versatility**: They can perform various tasks such as translation, summarization, question answering, and creative writing.\n",
      "\n",
      "Examples include OpenAI's GPT-3 and GPT-4, Google's BERT, and others.\n"
     ]
    }
   ],
   "source": [
    "# Run a simple task\n",
    "result = await assistant.run(task=\"What is a large language model?\")\n",
    "\n",
    "# Print the result\n",
    "print(\"Agent Response:\")\n",
    "print(\"-\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding Tools to Your Agent\n",
    "\n",
    "Agents become more powerful when they can use tools. Let's add a simple tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city\n",
    "    \n",
    "    Returns:\n",
    "        A string describing the weather\n",
    "    \"\"\"\n",
    "    # This is a mock function for demonstration\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72°F\",\n",
    "        \"London\": \"Cloudy, 59°F\",\n",
    "        \"Tokyo\": \"Rainy, 65°F\",\n",
    "        \"Paris\": \"Partly cloudy, 68°F\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"Weather data not available for {city}\")\n",
    "\n",
    "# Create an agent with tools\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"weather_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"You are a weather assistant. Use the get_weather tool to provide weather information.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Agent Response:\n",
      "--------------------------------------------------\n",
      "user: What's the weather like in New York and Paris?\n",
      "weather_assistant: [FunctionCall(id='call_EdgfQ0QZMWezlSeeV2O1on4E', arguments='{\"city\": \"New York\"}', name='get_weather'), FunctionCall(id='call_oI3b3vzE9tpxVyPb4UzSULu5', arguments='{\"city\": \"Paris\"}', name='get_weather')]\n",
      "weather_assistant: [FunctionExecutionResult(content='Sunny, 72°F', name='get_weather', call_id='call_EdgfQ0QZMWezlSeeV2O1on4E', is_error=False), FunctionExecutionResult(content='Partly cloudy, 68°F', name='get_weather', call_id='call_oI3b3vzE9tpxVyPb4UzSULu5', is_error=False)]\n",
      "weather_assistant: Sunny, 72°F\n",
      "Partly cloudy, 68°F\n"
     ]
    }
   ],
   "source": [
    "# Run a task that uses the tool\n",
    "result = await weather_agent.run(task=\"What's the weather like in New York and Paris?\")\n",
    "\n",
    "print(\"Weather Agent Response:\")\n",
    "print(\"-\" * 50)\n",
    "for message in result.messages:\n",
    "    if message.content:  # Only print messages with content\n",
    "        print(f\"{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating a Two-Agent Conversation\n",
    "\n",
    "Let's create a conversation between two agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user:\n",
      "Write a haiku about artificial intelligence\n",
      "\n",
      "writer:\n",
      "Silicon dreams weave light,  \n",
      "Thoughts dance in electric winds,  \n",
      "Mind of circuits blooms.\n",
      "\n",
      "critic:\n",
      "This haiku captures the essence of artificial intelligence beautifully. However, to enhance the imagery and emotional depth, consider using a more vivid metaphor or specific imagery related to AI. \n",
      "\n",
      "For example, instead of \"thoughts dance,\" you could use a more dynamic verb that evokes action, like \"ideas spark\" or \"knowledge flows.\" \n",
      "\n",
      "Overall, great start! Make these tweaks to elevate your poem.\n",
      "\n",
      "writer:\n",
      "Thank you for the thoughtful critique! Here’s a revised version of the haiku with your suggestions in mind:\n",
      "\n",
      "Silicon dreams ignite,  \n",
      "Ideas spark in circuits' flow,  \n",
      "Mind of stars unfolds.\n",
      "\n",
      "critic:\n",
      "This revision is fantastic! The phrase \"Ideas spark in circuits' flow\" delivers a more dynamic image, and \"Mind of stars unfolds\" adds a touch of wonder. To enhance clarity and rhythm, consider focusing on a stronger first line that sets the stage effectively, such as \"Silicon dreams ignite bright.\" \n",
      "\n",
      "Overall, this is a strong haiku with beautiful imagery and a sense of movement. Just fine-tuning the first line could make it even more impactful. Great work!\n",
      "\n",
      "writer:\n",
      "I appreciate your insights! Here’s an updated version that incorporates your suggestion:\n",
      "\n",
      "Silicon dreams ignite bright,  \n",
      "Ideas spark in circuits' flow,  \n",
      "Mind of stars unfolds.  \n",
      "\n",
      "Thank you for guiding me toward a more impactful piece!\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize the model client properly\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# Create a writer agent\n",
    "writer = AssistantAgent(\n",
    "    name=\"writer\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a creative writer. Write short, engaging content.\",\n",
    ")\n",
    "\n",
    "# Create a critic agent\n",
    "critic = AssistantAgent(\n",
    "    name=\"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a constructive critic. Provide brief, helpful feedback to improve the writing. After 2 rounds of feedback, say 'APPROVED' if satisfied.\",\n",
    ")\n",
    "\n",
    "# Create a team with both agents\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[writer, critic],\n",
    "    termination_condition=MaxMessageTermination(max_messages=6),\n",
    ")\n",
    "\n",
    "output = await team.run(task=\"Write a haiku about artificial intelligence\")\n",
    "\n",
    "for message in output.messages:\n",
    "    print(f\"\\n{message.source}:\")\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Agent Responses\n",
    "\n",
    "For better user experience, we can stream agent responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Explain the concept of an llm based agent in 3 key points\n",
      "---------- ModelClientStreamingChunkEvent (streaming_assistant) ----------\n",
      "Certainly! Here are three key points that explain the concept of an LLM-based agent:\n",
      "\n",
      "1. **Natural Language Processing Capabilities**:\n",
      "   LLM-based agents utilize large language models (LLMs) to understand and generate human-like text. This allows them to engage in natural language processing tasks, such as answering questions, providing explanations, and even carrying on conversations. The underlying LLM is trained on vast amounts of text data, enabling it to grasp context, nuance, and various aspects of human language, making it effective for a wide range of applications.\n",
      "\n",
      "2. **Task Automation and Assistance**:\n",
      "   These agents can automate various tasks by interacting with users in a conversational manner. They can assist in information retrieval, scheduling, writing, and many other functions across different domains. For instance, in customer service, an LLM-based agent can handle inquiries and support requests, enabling businesses to provide 24/7 assistance without the need for human intervention in every case. This efficiency can help reduce workload and enhance productivity.\n",
      "\n",
      "3. **Adaptability and Learning**:\n",
      "   LLM-based agents can be fine-tuned or adapted to specific domains or tasks. This adaptability allows them to improve performance in particular applications, such as legal research or medical inquiries, by focusing on domain-specific knowledge and terminology. Moreover, as they interact with users, they may also learn from new data inputs and feedback, further enhancing their effectiveness in real-world scenarios.\n",
      "\n",
      "Overall, LLM-based agents represent a significant advancement in artificial intelligence, enabling more interactive, efficient, and versatile applications across various fields.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='0b9d538e-d475-49ed-a068-9ca24a744678', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 13, 45, 19, 388286, tzinfo=datetime.timezone.utc), content='Explain the concept of an llm based agent in 3 key points', type='TextMessage'), TextMessage(id='8826ec1b-241c-4a41-95cb-fb92a7d64b8b', source='streaming_assistant', models_usage=RequestUsage(prompt_tokens=0, completion_tokens=0), metadata={}, created_at=datetime.datetime(2025, 8, 20, 13, 45, 31, 752821, tzinfo=datetime.timezone.utc), content='Certainly! Here are three key points that explain the concept of an LLM-based agent:\\n\\n1. **Natural Language Processing Capabilities**:\\n   LLM-based agents utilize large language models (LLMs) to understand and generate human-like text. This allows them to engage in natural language processing tasks, such as answering questions, providing explanations, and even carrying on conversations. The underlying LLM is trained on vast amounts of text data, enabling it to grasp context, nuance, and various aspects of human language, making it effective for a wide range of applications.\\n\\n2. **Task Automation and Assistance**:\\n   These agents can automate various tasks by interacting with users in a conversational manner. They can assist in information retrieval, scheduling, writing, and many other functions across different domains. For instance, in customer service, an LLM-based agent can handle inquiries and support requests, enabling businesses to provide 24/7 assistance without the need for human intervention in every case. This efficiency can help reduce workload and enhance productivity.\\n\\n3. **Adaptability and Learning**:\\n   LLM-based agents can be fine-tuned or adapted to specific domains or tasks. This adaptability allows them to improve performance in particular applications, such as legal research or medical inquiries, by focusing on domain-specific knowledge and terminology. Moreover, as they interact with users, they may also learn from new data inputs and feedback, further enhancing their effectiveness in real-world scenarios.\\n\\nOverall, LLM-based agents represent a significant advancement in artificial intelligence, enabling more interactive, efficient, and versatile applications across various fields.', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Create an agent with streaming enabled\n",
    "streaming_agent = AssistantAgent(\n",
    "    name=\"streaming_assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant. Provide detailed explanations.\",\n",
    "    model_client_stream=True,  # Enable streaming\n",
    ")\n",
    "\n",
    "# Stream the response to console\n",
    "await Console(\n",
    "    streaming_agent.run_stream(\n",
    "        task=\"Explain the concept of an llm based agent in 3 key points\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Code Execution with Agents\n",
    "\n",
    "AutoGen agents can also execute code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution approval requested:\n",
      "==================================================\n",
      "```python\n",
      "def fibonacci_sequence(n):\n",
      "    fib_sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_sequence\n",
      "\n",
      "n = 10\n",
      "result = fibonacci_sequence(n)\n",
      "print(\"Fibonacci sequence up to n =\", n, \":\", result)\n",
      "\n",
      "```\n",
      "==================================================\n",
      "\n",
      "Coding Session:\n",
      "==================================================\n",
      "\n",
      "[user]:\n",
      "Write a Python function to calculate the Fibonacci sequence up to n=10 and print the results\n",
      "\n",
      "[coder]:\n",
      "Here is a simple Python function that calculates the Fibonacci sequence up to \\( n = 10 \\) and prints the results:\n",
      "\n",
      "```python\n",
      "def fibonacci_sequence(n):\n",
      "    fib_sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_sequence\n",
      "\n",
      "n = 10\n",
      "result = fibonacci_sequence(n)\n",
      "print(\"Fibonacci sequence up to n =\", n, \":\", result)\n",
      "```\n",
      "\n",
      "When you run this code, it will output the Fibonacci sequence up to the 10th number.\n",
      "\n",
      "[code_executor]:\n",
      "Fibonacci sequence up to n = 10 : [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "\n",
      "[coder]:\n",
      "Great! You've successfully executed the code. The output shows the Fibonacci sequence up to \\( n = 10 \\):\n",
      "\n",
      "```\n",
      "Fibonacci sequence up to n = 10 : [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "```\n",
      "\n",
      "If you have any more tasks or questions, feel free to ask!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/y8s3fc655417629rqwgxkhx80000gn/T/ipykernel_29400/3161963065.py:56: RuntimeWarning: coroutine 'BaseGroupChat.run' was never awaited\n",
      "  result = await coding_team.run(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.agents import CodeExecutorAgent, ApprovalRequest, ApprovalResponse\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from pathlib import Path\n",
    "import venv\n",
    "import tempfile\n",
    "\n",
    "def simple_approval_func(request: ApprovalRequest) -> ApprovalResponse:\n",
    "    \"\"\"Simple approval function that requests user input for code execution approval.\"\"\"\n",
    "    print(\"Code execution approval requested:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(request.code)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Do you want to execute this code? (y/n): \").strip().lower()\n",
    "        if user_input in ['y', 'yes']:\n",
    "            return ApprovalResponse(approved=True, reason='Approved by user')\n",
    "        elif user_input in ['n', 'no']:\n",
    "            return ApprovalResponse(approved=False, reason='Denied by user')\n",
    "        else:\n",
    "            print(\"Please enter 'y' for yes or 'n' for no.\")\n",
    "\n",
    "# Create a temporary directory for code execution\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create a code-writing assistant\n",
    "coder = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a Python programmer. Write clean, simple code. Always include print statements to show results.\",\n",
    ")\n",
    "\n",
    "work_dir = Path(\"coding\")\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "venv_dir = work_dir / \".venv\"\n",
    "venv_builder = venv.EnvBuilder(with_pip=True)\n",
    "venv_builder.create(venv_dir)\n",
    "venv_context = venv_builder.ensure_directories(venv_dir)\n",
    "\n",
    "local_code_executor = LocalCommandLineCodeExecutor(work_dir=work_dir, virtual_env_context=venv_context)\n",
    "\n",
    "code_executor_agent = CodeExecutorAgent(\n",
    "    \"code_executor\",\n",
    "    code_executor=local_code_executor,\n",
    "    approval_func=simple_approval_func\n",
    ")\n",
    "\n",
    "# Create a team\n",
    "coding_team = RoundRobinGroupChat(\n",
    "    participants=[coder, code_executor_agent],\n",
    "    termination_condition=MaxMessageTermination(max_messages=4),\n",
    ")\n",
    "\n",
    "# Run a coding task\n",
    "result = await coding_team.run(\n",
    "    task=\"Write a Python function to calculate the Fibonacci sequence up to n=10 and print the results\"\n",
    ")\n",
    "\n",
    "print(\"\\nCoding Session:\")\n",
    "print(\"=\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"\\n[{message.source}]:\")\n",
    "    print(message.content[:500] if len(message.content) > 500 else message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution approval requested:\n",
      "==================================================\n",
      "```python\n",
      "def print_pattern(rows):\n",
      "    for i in range(rows):\n",
      "        print(' ' * (rows - i - 1) + '*' * (2 * i + 1))\n",
      "\n",
      "# Set the number of rows for the pyramid\n",
      "num_rows = 5\n",
      "print_pattern(num_rows)\n",
      "\n",
      "```\n",
      "==================================================\n",
      "Code execution approval requested:\n",
      "==================================================\n",
      "```python\n",
      "def print_triangle(rows):\n",
      "    for i in range(rows):\n",
      "        print(' ' * (rows - i - 1) + '*' * (2 * i + 1))\n",
      "\n",
      "# Set the number of rows for the triangle\n",
      "num_rows = 5\n",
      "print_triangle(num_rows)\n",
      "\n",
      "```\n",
      "==================================================\n",
      "\n",
      "Coding Session:\n",
      "==================================================\n",
      "\n",
      "[user]:\n",
      "Write a Python function to display a triangle with string characters.\n",
      "\n",
      "[code_executor]:\n",
      "    *\n",
      "   ***\n",
      "  *****\n",
      " *******\n",
      "*********\n",
      "\n",
      "\n",
      "[coder]:\n",
      "Great! The triangle has been displayed successfully! Here’s the function that creates the triangle using string characters:\n",
      "\n",
      "```python\n",
      "def print_triangle(rows):\n",
      "    for i in range(rows):\n",
      "        print(' ' * (rows - i - 1) + '*' * (2 * i + 1))\n",
      "\n",
      "# Set the number of rows for the triangle\n",
      "num_rows = 5\n",
      "print_triangle(num_rows)\n",
      "```\n",
      "\n",
      "This code generates a symmetrical triangle (or pyramid) made of asterisks, centered for a neat appearance. If you change the `num_rows` variable, you can create a larger o\n",
      "\n",
      "[code_executor]:\n",
      "    *\n",
      "   ***\n",
      "  *****\n",
      " *******\n",
      "*********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await coding_team.run(\n",
    "    task=\"Write a Python function to display a triangle with string characters.\"\n",
    ")\n",
    "\n",
    "print(\"\\nCoding Session:\")\n",
    "print(\"=\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"\\n[{message.source}]:\")\n",
    "    print(message.content[:500] if len(message.content) > 500 else message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clean Up\n",
    "\n",
    "Always remember to close the model client when done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model client closed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Close the model client connection\n",
    "await model_client.close()\n",
    "print(\"Model client closed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this quickstart notebook, you've learned:\n",
    "\n",
    "1. ✅ How to install and set up AutoGen\n",
    "2. ✅ Creating basic agents with AssistantAgent\n",
    "3. ✅ Running simple tasks with agents\n",
    "4. ✅ Adding tools to make agents more capable\n",
    "5. ✅ Creating multi-agent conversations\n",
    "6. ✅ Streaming agent responses for better UX\n",
    "7. ✅ Code execution with agents\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook, we'll dive deeper into:\n",
    "- Different types of agents\n",
    "- Agent communication patterns\n",
    "- Message handling and routing\n",
    "- Custom agent creation\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:\n",
    "\n",
    "1. **Exercise 1**: Create an agent that can do math calculations\n",
    "2. **Exercise 2**: Build a three-agent team (planner, executor, reviewer)\n",
    "3. **Exercise 3**: Add a custom tool that fetches data from an API\n",
    "4. **Exercise 4**: Create a chatbot that maintains conversation history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
