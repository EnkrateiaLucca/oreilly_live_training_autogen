{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autogen AgentChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-core\"\n",
    "%pip install -U \"autogen-agentchat\"\n",
    "%pip install \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async environment configured for Jupyter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    print(\"Async environment configured for Jupyter.\")\n",
    "except ImportError:\n",
    "    print(\"Please install nest_asyncio with `pip install nest_asyncio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "import os\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=21), content='Welcome to this Course about Autogen! How can I assist you today in learning about AI agents?', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant that helps students \\\n",
    "            understand how to build AI Agents! You always greet students \\\n",
    "                by saing 'Welcome to this Course about Autogen!'\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    response = await assistant.on_messages([TextMessage(content=\"Hello!\", source=\"user\")], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "# This allows running async code in Jupyter\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", seed=42, temperature=0)\n",
    "\n",
    "assistant_helper = AssistantAgent(\n",
    "    name=\"assistant_helper2\",\n",
    "    system_message = \"You are a helpful assistant\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "cancellation_token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='assistant_helper2', models_usage=RequestUsage(prompt_tokens=19, completion_tokens=10), content='Hello! How can I assist you today?', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "async def run_my_assistant():\n",
    "    response = await assistant_helper.on_messages([TextMessage(content=\"Hello!\", source=\"user\")], cancellation_token)\n",
    "    print(response)\n",
    "\n",
    "asyncio.run(run_my_assistant())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image is a description of \"AgentChat,\" a high-level API for building multi-agent applications. It is built on top of the `autogen-core` package. The text highlights that AgentChat is suitable for beginners, while advanced users can benefit from the flexibility of `autogen-core`. It mentions features like Agents with preset behaviors and Teams with predefined multi-agent design patterns. There are sections for Installation, Quickstart, Tutorial, and Selector Group Chat, each providing guidance on different aspects of using AgentChat.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken, Image\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    message = MultiModalMessage(\n",
    "        content=[\"Here is an image:\", Image.from_file(Path(\"test.png\"))],\n",
    "        source=\"user\",\n",
    "    )\n",
    "    response = await assistant.on_messages([message], cancellation_token)\n",
    "    return response\n",
    "\n",
    "response = asyncio.run(main())\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def respond_questions_about_image(prompt) -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "    message = MultiModalMessage(\n",
    "        content=[f\"Respond this question: {prompt} about this image:\", Image.from_file(Path(\"test.png\"))],\n",
    "        source=\"user\",\n",
    "    )\n",
    "    response = await assistant.on_messages([message], cancellation_token)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=904, completion_tokens=27), content='The text underneath the \"Selector Group Chat\" area reads: \"Multi-agent coordination through a shared context and centralized, customizable selector.\"', type='TextMessage'), inner_messages=[])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = asyncio.run(respond_questions_about_image(prompt=\"What is written underneath the selector group chat area?\"))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text underneath the \"Selector Group Chat\" area reads: \"Multi-agent coordination through a shared context and centralized, customizable selector.\"'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def fetch_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "# Initialize the agent\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", seed=42, temperature=0)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You return weather information given a city name using the fetch_weather tool.\",\n",
    "    tools=[fetch_weather], # Register the tool function\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "output = await assistant.on_messages([TextMessage(content=\"What is the weather in San Francisco?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_IjeCslmPDdlnALDrWC9bfx1X', arguments='{\"city\":\"San Francisco\"}', name='fetch_weather')]\n",
      "[FunctionExecutionResult(content='The weather in San Francisco is sunny.', call_id='call_IjeCslmPDdlnALDrWC9bfx1X')]\n"
     ]
    }
   ],
   "source": [
    "for msg in output.inner_messages:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is sunny.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await assistant.on_messages([TextMessage(content=\"What is the weather in Lisbon?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_W9zcx38aeryEbrRu2QzNgp8n', arguments='{\"city\":\"Lisbon\"}', name='fetch_weather')]\n",
      "[FunctionExecutionResult(content='The weather in Lisbon is sunny.', call_id='call_W9zcx38aeryEbrRu2QzNgp8n')]\n"
     ]
    }
   ],
   "source": [
    "for msg in output.inner_messages:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "\n",
    "\n",
    "#!pip install yfinance matplotlib pytz numpy pandas python-dotenv requests bs4\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    search_engine_id = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": str(api_key), \"cx\": str(search_engine_id), \"q\": str(query), \"num\": str(num_results)}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results\n",
    "\n",
    "search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen_core.tools._function_tool.FunctionTool at 0x12980b210>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autogen_core.tools._function_tool.FunctionTool"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    tools=[search_tool],\n",
    "    description=\"Search Google for information, returns top 5 results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await search_agent.on_messages([TextMessage(content=\"Look up on google how to set up custom tools in Autogen Agentchat version 0.4.1?\", source=\"user\")], CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'title': 'microsoft/autogen: A programming framework for agentic AI ... - GitHub', 'link': 'https://github.com/microsoft/autogen', 'snippet': '... AutoGen framework and developer tools to create applications for your domain. For example, Magentic-One is a state-of-art multi-agent team built using AgentChat\\\\xa0...', 'body': 'GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code'}, {'title': 'AutoGen', 'link': 'https://www.reddit.com/r/AutoGenAI/', 'snippet': 'Sep 27, 2023 ... Update version to 0.4.1 by. @jackgerrits. in. #5029. Fixup autogen ... Set up redirects from gh-pages to new domain by. @harishmohanraj. in\\\\xa0...', 'body': 'Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising. By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper'}]\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "results = literal_eval(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'microsoft/autogen: A programming framework for agentic AI ... - GitHub',\n",
       "  'link': 'https://github.com/microsoft/autogen',\n",
       "  'snippet': '... AutoGen framework and developer tools to create applications for your domain. For example, Magentic-One is a state-of-art multi-agent team built using AgentChat\\xa0...',\n",
       "  'body': 'GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code'},\n",
       " {'title': 'AutoGen',\n",
       "  'link': 'https://www.reddit.com/r/AutoGenAI/',\n",
       "  'snippet': 'Sep 27, 2023 ... Update version to 0.4.1 by. @jackgerrits. in. #5029. Fixup autogen ... Set up redirects from gh-pages to new domain by. @harishmohanraj. in\\xa0...',\n",
       "  'body': 'Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising. By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: microsoft/autogen: A programming framework for agentic AI ... - GitHub\n",
      "Link: https://github.com/microsoft/autogen\n",
      "Snippet: ... AutoGen framework and developer tools to create applications for your domain. For example, Magentic-One is a state-of-art multi-agent team built using AgentChatÂ ...\n",
      "Body: GitHub - microsoft/autogen: A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour Skip to content Navi...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: AutoGen\n",
      "Link: https://www.reddit.com/r/AutoGenAI/\n",
      "Snippet: Sep 27, 2023 ... Update version to 0.4.1 by. @jackgerrits. in. #5029. Fixup autogen ... Set up redirects from gh-pages to new domain by. @harishmohanraj. inÂ ...\n",
      "Body: Reddit - Dive into anything Skip to main content We value your privacy Reddit and its partners use cookies and similar technologies to provide you with a better experience. By accepting all cookies, y...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loop through and print each result nicely formatted\n",
    "for result in results:\n",
    "    print(\"Title:\", result['title'])\n",
    "    print(\"Link:\", result['link'])\n",
    "    print(\"Snippet:\", result['snippet'])\n",
    "    print(\"Body:\", result['body'][:200] + \"...\")  # Print first 200 chars of body\n",
    "    print(\"-\" * 80)  # Print separator line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancellation tokenn is something you use to cancell the async calls during an agent's execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Cancellation Token?\n",
    "\n",
    "Token to cancel pending async calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation was cancelled.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "async def main():\n",
    "    # Initialize the model client\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "\n",
    "    # Create an instance of AssistantAgent\n",
    "    agent = AssistantAgent(name=\"assistant\", model_client=model_client)\n",
    "\n",
    "    # Create a cancellation token\n",
    "    cancellation_token = CancellationToken()\n",
    "\n",
    "    try:\n",
    "        # Start a task that will cancel the token after 3 seconds\n",
    "        asyncio.create_task(cancel_after_delay(cancellation_token, 3))\n",
    "\n",
    "        # Send a message to the agent with the cancellation token\n",
    "        response = await agent.on_messages(\n",
    "            [TextMessage(content=\"Write me a story about the history of Large Language Models\", source=\"user\")],\n",
    "            cancellation_token=cancellation_token,\n",
    "        )\n",
    "        print(response.chat_message.content)\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"The operation was cancelled.\")\n",
    "\n",
    "async def cancel_after_delay(cancellation_token, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    cancellation_token.cancel()\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancellation tokenn is something you use to cancell the async calls during an agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
