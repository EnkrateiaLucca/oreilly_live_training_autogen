{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with AutoGen\n",
    "\n",
    "## Welcome to AutoGen!\n",
    "\n",
    "AutoGen is a programming framework for building multi-agent AI applications. In this quickstart notebook, we'll:\n",
    "\n",
    "1. Install AutoGen\n",
    "2. Create your first agent\n",
    "3. Build a simple two-agent conversation\n",
    "4. Add tools and function calling\n",
    "5. Stream agent responses\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGen AgentChat and Extensions\n",
    "!pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up API Keys\n",
    "\n",
    "AutoGen works with various LLM providers. For this tutorial, we'll use OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your OpenAI API key\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Your First Agent\n",
    "\n",
    "Let's create a simple assistant agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize the model client\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ[\"OPENAI_API_KEY\"],  # Optional, will use env var\n",
    ")\n",
    "\n",
    "# Create an assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant. Be concise and informative.\",\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Your First Agent Task\n",
    "\n",
    "Now let's run a simple task with our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "--------------------------------------------------\n",
      "user: What is a large language model?\n",
      "helpful_assistant: A large language model (LLM) is a type of artificial intelligence that is trained on vast amounts of text data to understand and generate human language. Key characteristics of LLMs include:\n",
      "\n",
      "1. **Scale**: LLMs have a large number of parameters (often billions or trillions), which allows them to capture complex patterns and nuances in language.\n",
      "\n",
      "2. **Training**: They are trained using machine learning techniques, particularly deep learning, on diverse datasets comprising books, articles, websites, and more.\n",
      "\n",
      "3. **Natural Language Understanding and Generation**: LLMs can perform tasks such as text completion, summarization, translation, conversation, and question-answering.\n",
      "\n",
      "4. **Contextual Awareness**: They can generate coherent and contextually relevant responses based on the input they receive.\n",
      "\n",
      "5. **Few-Shot and Zero-Shot Learning**: LLMs can often perform tasks with limited examples (few-shot) or even without explicit examples (zero-shot), leveraging their training to generalize to new contexts.\n",
      "\n",
      "Examples of large language models include OpenAI’s GPT (Generative Pre-trained Transformer) series, Google's BERT, and others. They are used in various applications like chatbots, content creation, and more across multiple industries.\n"
     ]
    }
   ],
   "source": [
    "# Run a simple task\n",
    "result = await assistant.run(task=\"What is a large language model?\")\n",
    "\n",
    "# Print the result\n",
    "print(\"Agent Response:\")\n",
    "print(\"-\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding Tools to Your Agent\n",
    "\n",
    "Agents become more powerful when they can use tools. Let's add a simple tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Agent Response:\n",
      "--------------------------------------------------\n",
      "user: What's the weather like in New York and Paris?\n",
      "weather_assistant: [FunctionCall(id='call_HcNdF4GyDJrmWdm07zQQxPIZ', arguments='{\"city\": \"New York\"}', name='get_weather'), FunctionCall(id='call_D9nIoTOwZ1kesy3ycPqSwHjX', arguments='{\"city\": \"Paris\"}', name='get_weather')]\n",
      "weather_assistant: [FunctionExecutionResult(content='Sunny, 72°F', name='get_weather', call_id='call_HcNdF4GyDJrmWdm07zQQxPIZ', is_error=False), FunctionExecutionResult(content='Partly cloudy, 68°F', name='get_weather', call_id='call_D9nIoTOwZ1kesy3ycPqSwHjX', is_error=False)]\n",
      "weather_assistant: Sunny, 72°F\n",
      "Partly cloudy, 68°F\n"
     ]
    }
   ],
   "source": [
    "# Define a simple tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city\n",
    "    \n",
    "    Returns:\n",
    "        A string describing the weather\n",
    "    \"\"\"\n",
    "    # This is a mock function for demonstration\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72°F\",\n",
    "        \"London\": \"Cloudy, 59°F\",\n",
    "        \"Tokyo\": \"Rainy, 65°F\",\n",
    "        \"Paris\": \"Partly cloudy, 68°F\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"Weather data not available for {city}\")\n",
    "\n",
    "# Create an agent with tools\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"weather_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"You are a weather assistant. Use the get_weather tool to provide weather information.\",\n",
    ")\n",
    "\n",
    "# Run a task that uses the tool\n",
    "result = await weather_agent.run(task=\"What's the weather like in New York and Paris?\")\n",
    "\n",
    "print(\"Weather Agent Response:\")\n",
    "print(\"-\" * 50)\n",
    "for message in result.messages:\n",
    "    if message.content:  # Only print messages with content\n",
    "        print(f\"{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating a Two-Agent Conversation\n",
    "\n",
    "Let's create a conversation between two agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation:\n",
      "==================================================\n",
      "\n",
      "user:\n",
      "Write a haiku about artificial intelligence\n",
      "\n",
      "writer:\n",
      "Silicon whispers,  \n",
      "Thoughts woven in circuits' dance,  \n",
      "Dreams of code and light.\n",
      "\n",
      "critic:\n",
      "This haiku presents a beautiful imagery of artificial intelligence. To enhance it further, consider refining the emotional connection. Perhaps emphasize the impact of AI on human experience or its potential. \n",
      "\n",
      "Additionally, ensure the syllable count adheres strictly to the 5-7-5 structure. \n",
      "\n",
      "Here’s a suggestion for your second version: \n",
      "- Could you explore the relationship between humans and AI? \n",
      "\n",
      "Great job overall! Looking forward to seeing the improvements.\n",
      "\n",
      "writer:\n",
      "In shadows we share,  \n",
      "Logic breathes, yet hearts entwine,  \n",
      "Future's hand in ours.\n",
      "\n",
      "critic:\n",
      "This haiku effectively captures the human connection to artificial intelligence, evoking a sense of partnership. The imagery of \"shadows\" and \"hearts entwine\" is particularly evocative. \n",
      "\n",
      "To enhance it even more, consider playing with the first line for clarity or resonance, as \"In shadows we share\" might feel a bit vague. Perhaps you could clarify what is being shared, or evoke a more vivid picture to set the scene.\n",
      "\n",
      "Overall, great work on this revised version! One more tweak can elevate it further. Looking forward to your next iteration!\n",
      "\n",
      "writer:\n",
      "In bright screens we meet,  \n",
      "Logic breathes, yet hearts entwine,  \n",
      "Future's hand in ours.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "\n",
    "# Create a writer agent\n",
    "writer = AssistantAgent(\n",
    "    name=\"writer\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a creative writer. Write short, engaging content.\",\n",
    ")\n",
    "\n",
    "# Create a critic agent\n",
    "critic = AssistantAgent(\n",
    "    name=\"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a constructive critic. Provide brief, helpful feedback to improve the writing. After 2 rounds of feedback, say 'APPROVED' if satisfied.\",\n",
    ")\n",
    "\n",
    "# Create a team with both agents\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[writer, critic],\n",
    "    termination_condition=MaxMessageTermination(max_messages=6),\n",
    ")\n",
    "\n",
    "# Run the team\n",
    "result = await team.run(task=\"Write a haiku about artificial intelligence\")\n",
    "\n",
    "print(\"\\nConversation:\")\n",
    "print(\"=\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"\\n{message.source}:\")\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Agent Responses\n",
    "\n",
    "For better user experience, we can stream agent responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Explain the concept of an llm based agent in 3 key points\n",
      "---------- ModelClientStreamingChunkEvent (streaming_assistant) ----------\n",
      "An LLM-based agent refers to an intelligent system or digital assistant that utilizes a Large Language Model (LLM) to understand and generate human-like text. Here are three key points that encapsulate the concept:\n",
      "\n",
      "1. **Natural Language Understanding and Generation**: LLM-based agents are designed to comprehend and produce human language at a high level of sophistication. They leverage vast amounts of text data from various sources to learn the nuances of language, including grammar, context, and semantics. This ability allows them to understand user inputs, interpret intentions, and generate coherent and contextually appropriate responses, making interactions feel more intuitive and engaging.\n",
      "\n",
      "2. **Contextual Awareness and Memory**: These agents can maintain context over the course of a conversation, allowing for more meaningful and fluid exchanges. Advanced LLMs can track the thematic elements of a discussion, remember past interactions, and respond in a manner that reflects an understanding of prior context. This contextual awareness enhances the user experience by making interactions more relevant and personalized.\n",
      "\n",
      "3. **Versatile Applications Across Domains**: LLM-based agents can be deployed in a wide range of applications including customer support, content creation, tutoring, and more. Their versatility stems from their ability to adapt to various subjects and user needs, providing answers, recommendations, and assistance across multiple fields and industries. This adaptability, combined with their natural language capabilities, makes them valuable tools in enhancing productivity and engagement in both personal and professional settings.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='84a0e989-f37e-46ba-b5c8-2dc21f85925f', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 20, 9, 27, 55, 37547, tzinfo=datetime.timezone.utc), content='Explain the concept of an llm based agent in 3 key points', type='TextMessage'), TextMessage(id='9451e867-6f4a-45cc-8fcf-7aba3d424f22', source='streaming_assistant', models_usage=RequestUsage(prompt_tokens=0, completion_tokens=0), metadata={}, created_at=datetime.datetime(2025, 8, 20, 9, 28, 0, 380446, tzinfo=datetime.timezone.utc), content='An LLM-based agent refers to an intelligent system or digital assistant that utilizes a Large Language Model (LLM) to understand and generate human-like text. Here are three key points that encapsulate the concept:\\n\\n1. **Natural Language Understanding and Generation**: LLM-based agents are designed to comprehend and produce human language at a high level of sophistication. They leverage vast amounts of text data from various sources to learn the nuances of language, including grammar, context, and semantics. This ability allows them to understand user inputs, interpret intentions, and generate coherent and contextually appropriate responses, making interactions feel more intuitive and engaging.\\n\\n2. **Contextual Awareness and Memory**: These agents can maintain context over the course of a conversation, allowing for more meaningful and fluid exchanges. Advanced LLMs can track the thematic elements of a discussion, remember past interactions, and respond in a manner that reflects an understanding of prior context. This contextual awareness enhances the user experience by making interactions more relevant and personalized.\\n\\n3. **Versatile Applications Across Domains**: LLM-based agents can be deployed in a wide range of applications including customer support, content creation, tutoring, and more. Their versatility stems from their ability to adapt to various subjects and user needs, providing answers, recommendations, and assistance across multiple fields and industries. This adaptability, combined with their natural language capabilities, makes them valuable tools in enhancing productivity and engagement in both personal and professional settings.', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Create an agent with streaming enabled\n",
    "streaming_agent = AssistantAgent(\n",
    "    name=\"streaming_assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant. Provide detailed explanations.\",\n",
    "    model_client_stream=True,  # Enable streaming\n",
    ")\n",
    "\n",
    "# Stream the response to console\n",
    "await Console(\n",
    "    streaming_agent.run_stream(\n",
    "        task=\"Explain the concept of an llm based agent in 3 key points\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Code Execution with Agents\n",
    "\n",
    "AutoGen agents can also execute code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution approval requested:\n",
      "==================================================\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_sequence\n",
      "\n",
      "n = 10\n",
      "result = fibonacci(n)\n",
      "print(f\"The Fibonacci sequence up to n={n} is: {result}\")\n",
      "\n",
      "```\n",
      "==================================================\n",
      "\n",
      "Coding Session:\n",
      "==================================================\n",
      "\n",
      "[user]:\n",
      "Write a Python function to calculate the Fibonacci sequence up to n=10 and print the results\n",
      "\n",
      "[coder]:\n",
      "Sure! Here's a simple Python function that calculates the Fibonacci sequence up to the 10th number and prints the results:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_sequence\n",
      "\n",
      "n = 10\n",
      "result = fibonacci(n)\n",
      "print(f\"The Fibonacci sequence up to n={n} is: {result}\")\n",
      "```\n",
      "\n",
      "When you run this code, it will display the Fibonacci sequence up to the 10th number.\n",
      "\n",
      "[code_executor]:\n",
      "The Fibonacci sequence up to n=10 is: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "\n",
      "[coder]:\n",
      "Great! It looks like the function worked perfectly. The output shows the Fibonacci sequence up to the 10th number: \n",
      "\n",
      "```\n",
      "The Fibonacci sequence up to n=10 is: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "```\n",
      "\n",
      "If you have any further questions or need additional modifications, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.agents import CodeExecutorAgent, ApprovalRequest, ApprovalResponse\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from pathlib import Path\n",
    "import venv\n",
    "import tempfile\n",
    "\n",
    "def simple_approval_func(request: ApprovalRequest) -> ApprovalResponse:\n",
    "    \"\"\"Simple approval function that requests user input for code execution approval.\"\"\"\n",
    "    print(\"Code execution approval requested:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(request.code)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Do you want to execute this code? (y/n): \").strip().lower()\n",
    "        if user_input in ['y', 'yes']:\n",
    "            return ApprovalResponse(approved=True, reason='Approved by user')\n",
    "        elif user_input in ['n', 'no']:\n",
    "            return ApprovalResponse(approved=False, reason='Denied by user')\n",
    "        else:\n",
    "            print(\"Please enter 'y' for yes or 'n' for no.\")\n",
    "\n",
    "# Create a temporary directory for code execution\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create a code-writing assistant\n",
    "coder = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a Python programmer. Write clean, simple code. Always include print statements to show results.\",\n",
    ")\n",
    "\n",
    "work_dir = Path(\"coding\")\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "venv_dir = work_dir / \".venv\"\n",
    "venv_builder = venv.EnvBuilder(with_pip=True)\n",
    "venv_builder.create(venv_dir)\n",
    "venv_context = venv_builder.ensure_directories(venv_dir)\n",
    "\n",
    "local_code_executor = LocalCommandLineCodeExecutor(work_dir=work_dir, virtual_env_context=venv_context)\n",
    "\n",
    "code_executor_agent = CodeExecutorAgent(\n",
    "    \"code_executor\",\n",
    "    code_executor=local_code_executor,\n",
    "        approval_func=simple_approval_func\n",
    ")\n",
    "\n",
    "# Create a team\n",
    "coding_team = RoundRobinGroupChat(\n",
    "    participants=[coder, code_executor_agent],\n",
    "    termination_condition=MaxMessageTermination(max_messages=4),\n",
    ")\n",
    "\n",
    "# Run a coding task\n",
    "result = await coding_team.run(\n",
    "    task=\"Write a Python function to calculate the Fibonacci sequence up to n=10 and print the results\"\n",
    ")\n",
    "\n",
    "print(\"\\nCoding Session:\")\n",
    "print(\"=\" * 50)\n",
    "for message in result.messages:\n",
    "    print(f\"\\n[{message.source}]:\")\n",
    "    print(message.content[:500] if len(message.content) > 500 else message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clean Up\n",
    "\n",
    "Always remember to close the model client when done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the model client connection\n",
    "await model_client.close()\n",
    "print(\"Model client closed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this quickstart notebook, you've learned:\n",
    "\n",
    "1. ✅ How to install and set up AutoGen\n",
    "2. ✅ Creating basic agents with AssistantAgent\n",
    "3. ✅ Running simple tasks with agents\n",
    "4. ✅ Adding tools to make agents more capable\n",
    "5. ✅ Creating multi-agent conversations\n",
    "6. ✅ Streaming agent responses for better UX\n",
    "7. ✅ Code execution with agents\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook, we'll dive deeper into:\n",
    "- Different types of agents\n",
    "- Agent communication patterns\n",
    "- Message handling and routing\n",
    "- Custom agent creation\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:\n",
    "\n",
    "1. **Exercise 1**: Create an agent that can do math calculations\n",
    "2. **Exercise 2**: Build a three-agent team (planner, executor, reviewer)\n",
    "3. **Exercise 3**: Add a custom tool that fetches data from an API\n",
    "4. **Exercise 4**: Create a chatbot that maintains conversation history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
