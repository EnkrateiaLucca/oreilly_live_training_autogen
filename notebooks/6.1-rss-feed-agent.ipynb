{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS Feed Agent\n",
    "\n",
    "1. Write up the tools necessary to:\n",
    "   1. Search websites for new info\n",
    "   2. Write an organized report to a file\n",
    "2. Write up the agents and setup their communication\n",
    "3. Test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    \n",
    "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": os.environ[\"GOOGLE_API_KEY\"],\n",
    "        \"cx\": os.environ[\"GOOGLE_CSE_ID\"],\n",
    "        \"q\": query,\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "        \n",
    "    results = response.json().get(\"items\", [])\n",
    "    \n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            return text[:max_chars]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "            \n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append({\n",
    "            \"title\": item[\"title\"],\n",
    "            \"link\": item[\"link\"], \n",
    "            \"snippet\": item[\"snippet\"],\n",
    "            \"body\": body\n",
    "        })\n",
    "        time.sleep(1)\n",
    "        \n",
    "    return enriched_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = google_search(\"hacker news AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'How I Use \"AI\" | Hacker News', 'link': 'https://news.ycombinator.com/item?id=41150317', 'snippet': \"As a device for speeding up learning, they're incredible. Best of all, they're strongest where I'm weakest: finding all the arbitrary details that are needed\\xa0...\", 'body': 'How I Use \"AI\" | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login How I Use \"AI\" ( carlini.com ) 462 points by npalli 5 months ago | hide | past | favorite | 180\\xa0comments tptacek 5 months ago | next [–] There\\'s a running theme in here of programming problems LLMs solve where it\\'s actually not that important that the LLM is perfectly correct. I\\'ve been using GPT4 for the past couple months to comprehend Linux kernel code; it\\'s spooky good at it. I\\'m a C programmer,'}\n",
      "{'title': 'What it feels like to work in AI right now | Hacker News', 'link': 'https://news.ycombinator.com/item?id=35469908', 'snippet': \"Apr 6, 2023 ... Yes, that's called 'ensembling'. There is a lot of work being done on this kind of solution. One way in which it could work is that you can use\\xa0...\", 'body': 'What it feels like to work in AI right now | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login What it feels like to work in AI right now ( robotic.substack.com ) 350 points by pps on April 6, 2023 | hide | past | favorite | 737\\xa0comments cgearhart on April 7, 2023 | next [–] From my perspective it’s just _confusing_ to work in AI right now. We have some massive models that are doing some really neat stuff, and apparently hundreds of millions of people are using the'}\n"
     ]
    }
   ],
   "source": [
    "for result in output:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(summary_insights: str, report_file: str):\n",
    "    \"\"\"\n",
    "    Write a summary of the insights to a file\n",
    "    \"\"\"\n",
    "    with open(report_file, \"w\") as f:\n",
    "        f.write(summary_insights)\n",
    "\n",
    "write_report(\"AI is the future\", \"report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "\n",
    "search_tool = FunctionTool(\n",
    "    func=google_search,\n",
    "    name=\"search_tool\",\n",
    "    description=\"Search the web for information\",\n",
    ")\n",
    "\n",
    "write_report_tool = FunctionTool(\n",
    "    func=write_report,\n",
    "    name=\"write_report_tool\",\n",
    "    description=\"Write a summary of the insights to a file\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build out Agents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have 3 agents:\n",
    "1. To Search the web\n",
    "2. The extract insights from web results\n",
    "3. Write those insights to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = AssistantAgent(\n",
    "    name=\"search_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "    ),\n",
    "    system_message=\"You research the web for information and you communicate your findings to the insights_agent\",\n",
    "    tools=[search_tool],\n",
    ")\n",
    "\n",
    "model_client_structured = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "insights_agent = AssistantAgent(\n",
    "    name=\"insights_agent\",\n",
    "    model_client=model_client_structured,\n",
    "    system_message=\"You 10 extract insights from the web results and you communicate your findings to the write_report_agent using a json structure.\",\n",
    ")\n",
    "\n",
    "write_report_agent = AssistantAgent(\n",
    "    name=\"write_report_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "    ),\n",
    "    system_message=\"You write a report from the insights provided by the insights_agent using the write_report_tool. You always output\\\n",
    "        the word 'DONE' when you are finished.\",\n",
    "    tools=[write_report_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import TextMentionTermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Search hacker news for the latest open source LLMs and extact the best insights about the latest models into a file and call it rss-feed-do.md', type='TextMessage'), ToolCallRequestEvent(source='search_agent', models_usage=RequestUsage(prompt_tokens=135, completion_tokens=32), content=[FunctionCall(id='call_eWWLbueFAO9hYltsW6fmuFFL', arguments='{\"query\":\"site:news.ycombinator.com open source LLMs\",\"num_results\":5}', name='search_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='search_agent', models_usage=None, content=[FunctionExecutionResult(content='[{\\'title\\': \\'In the LLM space, \"open source\" is being used to mean ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=36815255\\', \\'snippet\\': \"Jul 21, 2023 ... LLaMA is not open weights. It\\'s a closed, proprietary set of weights[0] that at best could be compared to source available software.\", \\'body\\': \\'In the LLM space, \"open source\" is being used to mean \"downloadable weights\" | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login In the LLM space, \"open source\" is being used to mean \"downloadable weights\" ( alessiofanelli.com ) 400 points by FanaHOVA on July 21, 2023 | hide | past | favorite | 228\\\\xa0comments danShumway on July 21, 2023 | next [–] > For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. This is\\'}, {\\'title\\': \\'Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=42404202\\', \\'snippet\\': \\'Dec 13, 2024 ... Just read this paragraph: \"In conclusion, while managing output size limitations in LLMs presents significant challenges, it also drives\\\\xa0...\\', \\'body\\': \\'Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source Software | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source Software ( souzatharsis.com ) 168 points by sebg 33 days ago | hide | past | favorite | 30\\\\xa0comments huqedato 33 days ago | next [–] I took a brief look into this guide. What surprises me is that it sounds like being generated with AI. Am I the only one who thinks so? Just read \\'}, {\\'title\\': \\'Show HN: Open-source LLM provider price comparison | Hacker News\\', \\'link\\': \\'https://news.ycombinator.com/item?id=41244648\\', \\'snippet\\': \\'We tested cold-starts, performance consistency, scalability, and cost-effectiveness for models like Llama2 7Bn & Stable Diffusion across different providers.\\', \\'body\\': \"Show HN: Open-source LLM provider price comparison | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Show HN: Open-source LLM provider price comparison ( github.com/arc53 ) 125 points by shelar1423 5 months ago | hide | past | favorite | 32\\\\xa0comments Looking for the cheapest place to deploy llama 3.1 model? Don\\'t worry we have found it so you don\\'t have to. yujonglee 5 months ago | next [–] Litellm maintains list of model infos here: https://github.com/BerriAI/lit\"}, {\\'title\\': \\'Show HN: I wrote an open-source browser alternative for Computer ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=42052432\\', \\'snippet\\': \\'Nov 5, 2024 ... I made Browser-Use, an open-source tool that lets (all Langchain supported) LLMs execute tasks directly in the browser just with function\\\\xa0...\\', \\'body\\': \\'Show HN: I wrote an open-source browser alternative for Computer Use for any LLM | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Show HN: I wrote an open-source browser alternative for Computer Use for any LLM ( github.com/gregpr07 ) 180 points by gregpr07 71 days ago | hide | past | favorite | 72\\\\xa0comments Hey HN, I made Browser-Use, an open-source tool that lets (all Langchain supported) LLMs execute tasks directly in the browser just with function calling. It\\'}, {\\'title\\': \\'How long can open-source LLMs truly promise on context length ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=36528362\\', \\'snippet\\': \\'Jun 29, 2023 ... Longer context without a model capable of utilizing the context to actually do things, is yeah, unsurprisingly, not useful.\\', \\'body\\': \"How long can open-source LLMs truly promise on context length? | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login How long can open-source LLMs truly promise on context length? ( lmsys.org ) 189 points by dacheng2 on June 29, 2023 | hide | past | favorite | 62\\\\xa0comments ianbutler on June 30, 2023 | next [–] I think this is more of an issue of smaller models with larger context aren\\'t a magic bullet and I\\'m not sure anyone really paying attention thought they would \"}]', call_id='call_eWWLbueFAO9hYltsW6fmuFFL')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='search_agent', models_usage=None, content='[{\\'title\\': \\'In the LLM space, \"open source\" is being used to mean ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=36815255\\', \\'snippet\\': \"Jul 21, 2023 ... LLaMA is not open weights. It\\'s a closed, proprietary set of weights[0] that at best could be compared to source available software.\", \\'body\\': \\'In the LLM space, \"open source\" is being used to mean \"downloadable weights\" | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login In the LLM space, \"open source\" is being used to mean \"downloadable weights\" ( alessiofanelli.com ) 400 points by FanaHOVA on July 21, 2023 | hide | past | favorite | 228\\\\xa0comments danShumway on July 21, 2023 | next [–] > For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. This is\\'}, {\\'title\\': \\'Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=42404202\\', \\'snippet\\': \\'Dec 13, 2024 ... Just read this paragraph: \"In conclusion, while managing output size limitations in LLMs presents significant challenges, it also drives\\\\xa0...\\', \\'body\\': \\'Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source Software | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Taming LLMs – A Practical Guide to LLM Pitfalls with Open Source Software ( souzatharsis.com ) 168 points by sebg 33 days ago | hide | past | favorite | 30\\\\xa0comments huqedato 33 days ago | next [–] I took a brief look into this guide. What surprises me is that it sounds like being generated with AI. Am I the only one who thinks so? Just read \\'}, {\\'title\\': \\'Show HN: Open-source LLM provider price comparison | Hacker News\\', \\'link\\': \\'https://news.ycombinator.com/item?id=41244648\\', \\'snippet\\': \\'We tested cold-starts, performance consistency, scalability, and cost-effectiveness for models like Llama2 7Bn & Stable Diffusion across different providers.\\', \\'body\\': \"Show HN: Open-source LLM provider price comparison | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Show HN: Open-source LLM provider price comparison ( github.com/arc53 ) 125 points by shelar1423 5 months ago | hide | past | favorite | 32\\\\xa0comments Looking for the cheapest place to deploy llama 3.1 model? Don\\'t worry we have found it so you don\\'t have to. yujonglee 5 months ago | next [–] Litellm maintains list of model infos here: https://github.com/BerriAI/lit\"}, {\\'title\\': \\'Show HN: I wrote an open-source browser alternative for Computer ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=42052432\\', \\'snippet\\': \\'Nov 5, 2024 ... I made Browser-Use, an open-source tool that lets (all Langchain supported) LLMs execute tasks directly in the browser just with function\\\\xa0...\\', \\'body\\': \\'Show HN: I wrote an open-source browser alternative for Computer Use for any LLM | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Show HN: I wrote an open-source browser alternative for Computer Use for any LLM ( github.com/gregpr07 ) 180 points by gregpr07 71 days ago | hide | past | favorite | 72\\\\xa0comments Hey HN, I made Browser-Use, an open-source tool that lets (all Langchain supported) LLMs execute tasks directly in the browser just with function calling. It\\'}, {\\'title\\': \\'How long can open-source LLMs truly promise on context length ...\\', \\'link\\': \\'https://news.ycombinator.com/item?id=36528362\\', \\'snippet\\': \\'Jun 29, 2023 ... Longer context without a model capable of utilizing the context to actually do things, is yeah, unsurprisingly, not useful.\\', \\'body\\': \"How long can open-source LLMs truly promise on context length? | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login How long can open-source LLMs truly promise on context length? ( lmsys.org ) 189 points by dacheng2 on June 29, 2023 | hide | past | favorite | 62\\\\xa0comments ianbutler on June 30, 2023 | next [–] I think this is more of an issue of smaller models with larger context aren\\'t a magic bullet and I\\'m not sure anyone really paying attention thought they would \"}]', type='ToolCallSummaryMessage'), TextMessage(source='insights_agent', models_usage=RequestUsage(prompt_tokens=1145, completion_tokens=469), content='{\\n  \"latest_open_source_llms\": [\\n    {\\n      \"title\": \"Open-source LLM provider price comparison\",\\n      \"link\": \"https://news.ycombinator.com/item?id=41244648\",\\n      \"insights\": [\\n        \"This article provides a comprehensive price comparison of different open-source LLMs across various providers.\",\\n        \"Test metrics included in the comparison are cold-starts, performance consistency, scalability, and cost-effectiveness.\",\\n        \"Models tested include Llama2 7Bn and Stable Diffusion, finding the cheapest deployment options.\",\\n        \"Highly relevant for developers or companies looking to optimize costs while deploying LLMs.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"I wrote an open-source browser alternative for Computer Use for any LLM\",\\n      \"link\": \"https://news.ycombinator.com/item?id=42052432\",\\n      \"insights\": [\\n        \"Introduces \\'Browser-Use\\', an open-source tool allowing LLMs (compatible with Langchain) to execute tasks directly in the browser.\",\\n        \"Enhances functionality by enabling LLMs to perform more advanced tasks with streamlined function calling.\",\\n        \"Useful for developers building browser-based applications integrating LLM capabilities.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"How long can open-source LLMs truly promise on context length?\",\\n      \"link\": \"https://news.ycombinator.com/item?id=36528362\",\\n      \"insights\": [\\n        \"Discusses the limitations of open-source LLMs concerning promised context lengths.\",\\n        \"The primary issue is that smaller models with increased context length do not necessarily equate to improved functionality.\",\\n        \"Highlights the importance of balanced model sizing for practical performance and usability.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"In the LLM space, \\\\\"open source\\\\\" is being used to mean \\\\\"downloadable weights\\\\\"\",\\n      \"link\": \"https://news.ycombinator.com/item?id=36815255\",\\n      \"insights\": [\\n        \"Explores the semantic shift where \\'open source\\' in LLMs often refers to \\'downloadable weights\\' rather than full-fledged open-source models.\",\\n        \"Commentary on the evolving definition within the community and its acceptance.\"\\n      ]\\n    }\\n  ]\\n}', type='TextMessage'), ToolCallRequestEvent(source='write_report_agent', models_usage=RequestUsage(prompt_tokens=1689, completion_tokens=367), content=[FunctionCall(id='call_iFXVodvRlD5AlChwSlbBLlec', arguments='{\"summary_insights\":\"### Open-source LLM provider price comparison\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=41244648)\\\\n- A comprehensive price comparison of open-source LLMs across various providers.\\\\n- Evaluates cold-starts, performance consistency, scalability, and cost-effectiveness.\\\\n- Includes models like Llama2 7Bn and Stable Diffusion, highlighting the most cost-effective deployment options.\\\\n- Essential for cost optimization in LLM deployments.\\\\n\\\\n### I wrote an open-source browser alternative for Computer Use for any LLM\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=42052432)\\\\n- Introduces \\'Browser-Use\\', a tool that lets LLMs execute tasks directly in the browser, supporting Langchain.\\\\n- Enhances LLM functionalities for advanced browser-based applications.\\\\n\\\\n### How long can open-source LLMs truly promise on context length?\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36528362)\\\\n- Analyzes the limitations of open-source LLMs in terms of extended context lengths.\\\\n- Discusses the balance needed in model sizing for effective functionality.\\\\n\\\\n### In the LLM space, \\\\\"open source\\\\\" is being used to mean \\\\\"downloadable weights\\\\\"\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36815255)\\\\n- Discusses the nuance where \\'open source\\' often implies \\'downloadable weights\\' in the LLM domain.\\\\n- Insights into the shifting definitions within the community.\",\"report_file\":\"rss-feed-do.md\"}', name='write_report_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='write_report_agent', models_usage=None, content=[FunctionExecutionResult(content='None', call_id='call_iFXVodvRlD5AlChwSlbBLlec')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='write_report_agent', models_usage=None, content='None', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='search_agent', models_usage=RequestUsage(prompt_tokens=1733, completion_tokens=427), content=[FunctionCall(id='call_bRpoK1PfNuUDhfAyCHgddY7y', arguments='{\"query\":\"open source LLMs insights from Hacker News\",\"num_results\":2,\"max_chars\":500}', name='search_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='search_agent', models_usage=None, content=[FunctionExecutionResult(content=\"[{'title': 'MM1: Methods, Analysis and Insights from Multimodal LLM Pre ...', 'link': 'https://news.ycombinator.com/item?id=39722498', 'snippet': 'Hacker News new | past | comments | ask | show | jobs | submit · login · MM1 ... A bit underwhelming compared to recent announcements like the open source Large\\\\xa0...', 'body': 'MM1: Methods, Analysis and Insights from Multimodal LLM Pre-training | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login MM1: Methods, Analysis and Insights from Multimodal LLM Pre-training ( arxiv.org ) 179 points by lord_sudo 10 months ago | hide | past | favorite | 60\\\\xa0comments nl 10 months ago | next [–] This is an awesome paper, and the somewhat negative sentiment in the discussion here is surprising. The ablation studies are well done, comprehensive and expens'}, {'title': 'Requests for Startups | Y Combinator', 'link': 'https://www.ycombinator.com/rfs', 'snippet': 'Ultimately, open source companies succeed when they become the standard choice for software engineers. ... Hacker News · Launch YC · YC Deals. Make something\\\\xa0...', 'body': 'Requests for Startups | Y Combinator About What Happens at YC? Apply YC Interview Guide FAQ People YC Blog Companies Startup Directory Founder Directory Launch YC Startup Jobs All Jobs ◦ Engineering ◦ Operations ◦ Marketing ◦ Sales Startup Job Guide YC Startup Jobs Blog Find a Co-Founder Library SAFE Resources Startup School Newsletter For Investors Hacker News Bookface Open main menu Apply for X2025 batch. Apply Requests for Startups At YC we often discuss ideas we’d like to see more people wor'}]\", call_id='call_bRpoK1PfNuUDhfAyCHgddY7y')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='search_agent', models_usage=None, content=\"[{'title': 'MM1: Methods, Analysis and Insights from Multimodal LLM Pre ...', 'link': 'https://news.ycombinator.com/item?id=39722498', 'snippet': 'Hacker News new | past | comments | ask | show | jobs | submit · login · MM1 ... A bit underwhelming compared to recent announcements like the open source Large\\\\xa0...', 'body': 'MM1: Methods, Analysis and Insights from Multimodal LLM Pre-training | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login MM1: Methods, Analysis and Insights from Multimodal LLM Pre-training ( arxiv.org ) 179 points by lord_sudo 10 months ago | hide | past | favorite | 60\\\\xa0comments nl 10 months ago | next [–] This is an awesome paper, and the somewhat negative sentiment in the discussion here is surprising. The ablation studies are well done, comprehensive and expens'}, {'title': 'Requests for Startups | Y Combinator', 'link': 'https://www.ycombinator.com/rfs', 'snippet': 'Ultimately, open source companies succeed when they become the standard choice for software engineers. ... Hacker News · Launch YC · YC Deals. Make something\\\\xa0...', 'body': 'Requests for Startups | Y Combinator About What Happens at YC? Apply YC Interview Guide FAQ People YC Blog Companies Startup Directory Founder Directory Launch YC Startup Jobs All Jobs ◦ Engineering ◦ Operations ◦ Marketing ◦ Sales Startup Job Guide YC Startup Jobs Blog Find a Co-Founder Library SAFE Resources Startup School Newsletter For Investors Hacker News Bookface Open main menu Apply for X2025 batch. Apply Requests for Startups At YC we often discuss ideas we’d like to see more people wor'}]\", type='ToolCallSummaryMessage'), TextMessage(source='insights_agent', models_usage=RequestUsage(prompt_tokens=2013, completion_tokens=418), content='{\\n  \"latest_open_source_llms\": [\\n    {\\n      \"title\": \"Open-source LLM provider price comparison\",\\n      \"link\": \"https://news.ycombinator.com/item?id=41244648\",\\n      \"insights\": [\\n        \"A comprehensive price comparison of various open-source LLM providers has been conducted.\",\\n        \"Metrics like cold-start performance, scalability, and cost-effectiveness are compared.\",\\n        \"The comparison includes models like Llama2 7Bn and Stable Diffusion.\",\\n        \"This resource is beneficial for optimizing deployment costs and performance for developers.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"I wrote an open-source browser alternative for Computer Use for any LLM\",\\n      \"link\": \"https://news.ycombinator.com/item?id=42052432\",\\n      \"insights\": [\\n        \"An open-source tool named \\'Browser-Use\\' allows LLMs to execute tasks in-browser.\",\\n        \"Supports LLMs backed by Langchain with streamlined function calling.\",\\n        \"Useful for developers looking to integrate LLM capabilities into browser-based applications.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"How long can open-source LLMs truly promise on context length?\",\\n      \"link\": \"https://news.ycombinator.com/item?id=36528362\",\\n      \"insights\": [\\n        \"The discussion highlights open-source LLM limitations concerning context length.\",\\n        \"Increasing context lengths in smaller models do not necessarily improve functionality.\",\\n        \"Emphasizes balancing model size with context length for effective usability.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"In the LLM space, \\'open source\\' is being used to mean \\'downloadable weights\\'\",\\n      \"link\": \"https://news.ycombinator.com/item?id=36815255\",\\n      \"insights\": [\\n        \"\\'Open source\\' in LLMs often implies \\'downloadable weights\\' instead of fully open-source models.\",\\n        \"The community is recognizing and increasingly accepting this semantic shift.\"\\n      ]\\n    }\\n  ]\\n}', type='TextMessage'), ToolCallRequestEvent(source='write_report_agent', models_usage=RequestUsage(prompt_tokens=2877, completion_tokens=352), content=[FunctionCall(id='call_MUbrP8eUQrPFv7LwQ4kIUTZk', arguments='{\"summary_insights\":\"### Open-source LLM provider price comparison\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=41244648)\\\\n- Provides a comprehensive price comparison of different open-source LLMs across providers.\\\\n- Factors considered include cold-starts, scalability, and cost-effectiveness.\\\\n- Evaluates models like Llama2 7Bn and Stable Diffusion, crucial for cost-optimization in LLM deployments.\\\\n\\\\n### I wrote an open-source browser alternative for Computer Use for any LLM\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=42052432)\\\\n- Introduction of \\'Browser-Use\\', enabling LLMs to perform tasks directly in the browser.\\\\n- Supports Langchain models with ease of function calling, enhancing browser-app integration.\\\\n\\\\n### How long can open-source LLMs truly promise on context length?\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36528362)\\\\n- Addresses open-source LLM challenges with extended context lengths.\\\\n- Balancing model size and context for practical application is emphasized.\\\\n\\\\n### In the LLM space, \\'open source\\' is being used to mean \\'downloadable weights\\'\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36815255)\\\\n- Examines the term \\'open source\\' often interpreted as \\'downloadable weights\\' in LLMs.\\\\n- Observations on this semantic change and its acceptance within the community.\",\"report_file\":\"rss-feed-do.md\"}', name='write_report_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='write_report_agent', models_usage=None, content=[FunctionExecutionResult(content='None', call_id='call_MUbrP8eUQrPFv7LwQ4kIUTZk')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='write_report_agent', models_usage=None, content='None', type='ToolCallSummaryMessage'), TextMessage(source='search_agent', models_usage=RequestUsage(prompt_tokens=2586, completion_tokens=466), content='Based on the latest insights from Hacker News regarding open-source LLMs, I\\'ve compiled a report with key findings and insights. Here\\'s the report in markdown format:\\n\\n# Latest Open-Source LLMs Insights\\n\\n## Open-source LLM Provider Price Comparison\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=41244648)\\n- This resource provides a comprehensive price comparison across different open-source LLM providers.\\n- The comparisons consider metrics such as cold-starts, performance consistency, scalability, and cost-effectiveness.\\n- The models included in the test are Llama2 7Bn and Stable Diffusion, aimed at finding the most cost-effective deployment solutions.\\n- This information is critical for developers or companies optimizing costs while deploying LLMs.\\n\\n## Open-source Browser Alternative for LLM Use\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=42052432)\\n- An innovative tool named \\'Browser-Use\\' allows for in-browser task execution by LLMs supported by Langchain.\\n- Simplifies advanced task creation with streamlined function calling.\\n- Especially useful for developers focusing on browser-based applications integrating LLM capabilities.\\n\\n## Limitations on Context Length in Open-source LLMs\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36528362)\\n- This article addresses the promises versus the practical limitations of the context length in open-source LLMs.\\n- Highlights that increasing context length in smaller models doesn’t necessarily lead to improved functionality.\\n- Stresses the importance of balancing model size and context for effective usability.\\n\\n## Evolution of the Term \"Open Source\" in LLMs\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36815255)\\n- Explores the semantic change where \\'open source\\' in LLMs is evolving to mean \\'downloadable weights\\' rather than fully open-source models.\\n- This shift is gradually being recognized and accepted within the community.\\n\\n---\\n\\nThese insights provide a snapshot of the current discussions and developments in the field of open-source large language models (LLMs). The focus ranges from cost optimization and deployment strategies to understanding the semantics of \"open source\" in the LLM context.', type='TextMessage'), TextMessage(source='insights_agent', models_usage=RequestUsage(prompt_tokens=2918, completion_tokens=473), content='{\\n  \"filename\": \"rss-feed-do.md\",\\n  \"content\": \"# Latest Open-Source LLMs Insights\\\\n\\\\n## Open-source LLM Provider Price Comparison\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=41244648)\\\\n- This resource provides a comprehensive price comparison across different open-source LLM providers.\\\\n- The comparisons consider metrics such as cold-starts, performance consistency, scalability, and cost-effectiveness.\\\\n- The models included in the test are Llama2 7Bn and Stable Diffusion, aimed at finding the most cost-effective deployment solutions.\\\\n- This information is critical for developers or companies optimizing costs while deploying LLMs.\\\\n\\\\n## Open-source Browser Alternative for LLM Use\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=42052432)\\\\n- An innovative tool named \\'Browser-Use\\' allows for in-browser task execution by LLMs supported by Langchain.\\\\n- Simplifies advanced task creation with streamlined function calling.\\\\n- Especially useful for developers focusing on browser-based applications integrating LLM capabilities.\\\\n\\\\n## Limitations on Context Length in Open-source LLMs\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36528362)\\\\n- This article addresses the promises versus the practical limitations of the context length in open-source LLMs.\\\\n- Highlights that increasing context length in smaller models doesn’t necessarily lead to improved functionality.\\\\n- Stresses the importance of balancing model size and context for effective usability.\\\\n\\\\n## Evolution of the Term \\\\\"Open Source\\\\\" in LLMs\\\\n- **Link:** [Hacker News](https://news.ycombinator.com/item?id=36815255)\\\\n- Explores the semantic change where \\'open source\\' in LLMs is evolving to mean \\'downloadable weights\\' rather than fully open-source models.\\\\n- This shift is gradually being recognized and accepted within the community.\\\\n\\\\n---\\\\n\\\\nThese insights provide a snapshot of the current discussions and developments in the field of open-source large language models (LLMs). The focus ranges from cost optimization and deployment strategies to understanding the semantics of \\\\\"open source\\\\\" in the LLM context.\"\\n}', type='TextMessage'), TextMessage(source='write_report_agent', models_usage=RequestUsage(prompt_tokens=4193, completion_tokens=61), content='I\\'ve compiled the latest insights regarding open-source LLMs from Hacker News and stored them in a file named `rss-feed-do.md`. The report includes discussions on cost comparisons, browser tools, context length limitations, and the semantic evolution of \"open source\" within the LLM community. \\n\\nDONE', type='TextMessage')], stop_reason=\"Text 'DONE' mentioned\")\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "do_team = RoundRobinGroupChat(\n",
    "    [search_agent, insights_agent, write_report_agent],\n",
    "    termination_condition=TextMentionTermination(text=\"DONE\"),\n",
    ")\n",
    "\n",
    "response = await do_team.run(task=\"Search hacker news for the latest open source LLMs and extact the best insights about the latest models into a file and call it rss-feed-do.md\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-autogen",
   "language": "python",
   "name": "oreilly-autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
