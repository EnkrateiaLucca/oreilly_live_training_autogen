{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e47c17",
   "metadata": {},
   "source": [
    "# Intro Agents from SCratch\n",
    "\n",
    "## 3 Levels\n",
    "\n",
    "1. LLMs + functions in prompt\n",
    "2. LLMs + structured outputs/function calling\n",
    "3. Agent loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73b156",
   "metadata": {},
   "source": [
    "### 1. LLMs + functions in prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa79bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you mean in AI? If so, a common progression of agent “levels” (by sophistication) is:\\n\\n- Simple reflex agents: Act on condition–action rules; no internal state.\\n- Model-based reflex agents: Keep an internal state (a model) to handle partial observability.\\n- Goal-based agents: Plan actions to achieve explicit goals.\\n- Utility-based agents: Choose actions that maximize a utility function (trade-offs, uncertainty).\\n- Learning agents: Improve their behavior over time by learning; can augment any of the above.\\n\\nIf you meant another domain (e.g., support tiers, real estate licensing, autonomy levels in robotics), tell me which and I’ll tailor the answer.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "get_response(\"Hi! What are the levels of agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d35ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write_file(\"test.txt\", \"Hello, world!\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_file(file_path, content):\n",
    "    \"\"\"Takes in a file path and content, and writes the content to the file\"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Takes in a file path and returns the content of the file\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def level1_agent_llm_and_functions_in_prompt(prompt):\n",
    "    function_info = \"\"\"\n",
    "    def write_file(file_path, content):\n",
    "        '''Takes in a file path and content, and writes the content to the file'''\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    def read_file(file_path):\n",
    "        '''Takes in a file path and returns the content of the file'''\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    \"\"\"\n",
    "    full_prompt_with_function_info = f\"\"\"\n",
    "    Take this request from a user: {prompt}.\n",
    "    If the request involves writing to a file or reading to a file,\n",
    "    you can output a call to these functions which you have access to: \n",
    "    {function_info}.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "                  {\"role\": \"user\", \"content\": full_prompt_with_function_info}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "level1_agent_llm_and_functions_in_prompt(\"Write a file called 'test.txt' with the content 'Hello, world!'\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3e8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('write_file(\"test.txt\", \"Hello, world!\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9ab54",
   "metadata": {},
   "source": [
    "## Level 2: LLMs + structured outputs/function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02c8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class WriteFileOperation(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the file to be written to or read from\")\n",
    "    content: str = Field(description=\"The content to be written to the file\")\n",
    "\n",
    "class ReadFileOperation(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the file to be written to or read from\")\n",
    "\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "              {\"role\": \"user\", \"content\": \"Write a file called 'test.txt' with the content 'Hello, world!'\"}],\n",
    "    response_format=WriteFileOperation)\n",
    "\n",
    "output_write_file_ops = response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf46fa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt\n",
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(output_write_file_ops.file_path)\n",
    "print(output_write_file_ops.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WriteFileOperation(file_path='level2agentoutput.txt', content='Level 2 works!')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def level2_agent_llm_structured(prompt):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "              {\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=WriteFileOperation)# Structured OUTPUT from the LLM!\n",
    "    output_args = response.choices[0].message.parsed\n",
    "    # FUNCTION CALLING!\n",
    "    write_file(output_args.file_path, output_args.content)\n",
    "    print(\"File was created!\")\n",
    "    return output_args\n",
    "\n",
    "level2_agent_llm_structured(\"Write a file called 'level2agentoutput.txt' with the content 'Level 2 works!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b0ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modern LLM agents are goal-directed systems built around large language models that can plan and act, not just chat. They interact with external tools, services, and environments to achieve outcomes, iterating through a loop of observing context, planning next steps, taking actions, and using the results to refine their approach. Architecturally, they pair an LLM with a function-calling layer for tools and APIs, a memory or state store, and policies that constrain behavior. This enables multi-step workflows such as analyzing datasets, booking travel, triaging support tickets, or orchestrating business processes end to end.\\n\\nTo stay grounded, agents often augment the model with retrieval so it can consult documents, knowledge bases, or the web before answering. Tool use spans calling APIs and databases, browsing, and writing or executing code in a sandbox to transform data or validate results. Many implementations decompose tasks into subgoals, track intermediate state, and emit structured outputs for downstream systems. Orchestrators can coordinate multiple specialized agents (for example, researcher, coder, tester) and hand off work, while guardrails enforce schemas, permissions, and organizational policies. Integration is typically done through structured function calls, JSON schemas, and event-driven workflows.\\n\\nDespite their versatility, LLM agents have limits: they can hallucinate, mishandle edge cases, and struggle with very long-horizon plans or ambiguous goals. Practical deployments rely on safeguards such as permissioning, human-in-the-loop review, sandboxed tool execution, rate limits, and continuous evaluation of task success and safety. Cost and latency are important, so designers cache results, reuse context, and adapt model size to task complexity. Good applications align with agent strengths—information synthesis, routine workflow automation, data wrangling, and software assistance—while avoiding high-stakes decisions without oversight. Looking ahead, better memory, more reliable planning, and tighter integration with enterprise systems and hardware will make agents more capable and trustworthy.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this as sample_input.txt\n",
    "response = get_response(\"Create a 3 paragraph exaplanation of modern llm agents\")\n",
    "write_file(\"sample_input.txt\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d912086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"read_file('sample_input.txt')\", 'Create a concise summary (3-5 sentences or bullet points) of the file’s main ideas, key points, and conclusions based on the content read in the previous step.', \"write_file('summary_file.txt', '<insert concise summary from previous step here>')\"]\n"
     ]
    }
   ],
   "source": [
    "class TaskList(BaseModel):\n",
    "    tasks: list[str] = Field(description=\"A list of tasks to be executed\")\n",
    "\n",
    "def level3_agent_loop(task_prompt):\n",
    "    task_list_prompt = f\"\"\"\n",
    "    Break this task into a list of tasks as function call strings (or just strings if no function call is needed). \n",
    "    \"\"\"\n",
    "    task_list_response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You take in tasks and you break them down into a python \\\n",
    "                   list of sub-tasks as function call strings (or just strings if no function call \\\n",
    "                   is needed). each element of the list should be a single function call or a string \\\n",
    "                   specifying a task to be done. The only allowed functions are: \\\n",
    "                   write_file(),\\\n",
    "                   read_file()\"},\n",
    "              {\"role\": \"user\", \"content\": task_prompt}],\n",
    "    response_format=TaskList)# Structured OUTPUT from the LLM!\n",
    "    task_list = task_list_response.choices[0].message.parsed.tasks\n",
    "    \n",
    "        \n",
    "prompt = \"Read the file: 'sample_input.txt' and write a summary of that file into a new file called 'summary_file.txt'\"\n",
    "level3_agent_loop(prompt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
